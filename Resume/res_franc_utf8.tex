\documentclass{jfpc-preprint}
%\documentclass{article}
\usepackage{etex}


\input{mycommands}

\annee{2015}
\titre{\posl: Un langage orienté parallèle pour modéliser des solveurs de contraintes}
%\title{Un langage orienté parallèle pour modéliser des solveurs de contraintes}

\auteurs{\ale} 
%\author{Alejandro REYES AMARO \and Eric MONFROY \and Florian RICHOUX\\LINA - UMR 6241, TASC - INRIA
%Universit\'{e} de Nantes,
% France\\\{alejandro.reyes, eric.monfroy, florian.richoux\}@univ-nantes.fr} 

 \institutions{
 LINA - UMR 6241, TASC - INRIA
 Universit\'{e} de Nantes,
  France.}

 \mels{alejandro.reyes@univ-nantes.fr} % \and vin@fromage.com}

\begin{document}
%\creationEntete

\maketitle

%\begin{resume} % environnement pour le résumé en français
%Cet exemple est là pour vous aider à utiliser le style LaTeX ``jfpc''. Ce style devrait permettre d'avoir des actes uniformes, avec des papiers qui ont tous à peu près la même allure, à condition que vous respectiez un tant soit peu les recommandations qui y sont faites.
%
%Si vous soumettez un article court (2 pages max) vous devrez tout de même écrire un résumé de quelques phrases (mais aussi court que possible) explicitant clairement la référence à l'article original dont est tiré le résumé.
%
%Si vous n'utilisez pas LaTeX, vous devrez reproduire une mise-en-page similaire avec votre éditeur de texte préféré. 
%\end{resume}

\begin{resume} % environnement pour le résumé en anglais
La technologie multi-c\oe ur et les architectures massivement parallèles sont de plus en plus accessibles à tous, à travers des matériaux comme le Xeon Phi ou les cartes GPU. Cette stratégie d'architecture a été communément adoptée par les producteurs pour faire face à la loi de Moore. Or, ces nouvelles architectures impliquent d'autres manières de concevoir et d'implémenter les algorithmes, pour exploiter complètement leur potentiel, en particulier dans le cas des solveurs de contraintes traitant de problèmes d'optimisation combinatoire.

Cette  thèse présente Parallel-Oriented Solver Language (\posl{}, prononcé "{\it  puzzle}") : un système pour construire des méta-heuristiques interconnectées travaillant en parallèle. Le but de ce travail est d'obtenir un système pour facilement construire des solveurs et réduire l'effort  de leur  développement en  proposant un mécanisme de réutilisation de code entre les différents solveurs. La nouveauté de cette approche porte sur le fait que l'on voit un solveur comme un ensemble de composants spécifiques, écris dans un langage orienté parallèle basé sur des opérateurs. \posl{}  permets aux composants d'un solveur d'être transmis et exécutés par d'autres  solveurs. Il propose également une couche supplémentaire permettant de définir des connexions entre solveurs.
\end{resume}


\section{Introduction}
\input{_introduction}

\section{Solveurs parallèles POSL}
\input{_posl}

\posl{} permet de construire des solveurs suivant différentes étapes : 
\begin{enumerate}
\item  L'algorithme du solveur considéré est  exprimé via une décomposition  en modules de calcul. Ces modules sont implémentés à la   manière de {\it fonctions} séparées. Nous appelons \INTROom{} ces morceaux de calcul (figure \ref{subfig:modules}, \new{blocs bleus}). \new{En suite, il faut décider  quelles  sont les  types d'informations que l'on souhaite  recevoir des autres solveurs.  Ces informations sont encapsulées  dans des composants appelés  \opch{},  permettant  de transmettre  des  données entre solveurs (figure \ref{subfig:modules}, \new{bloc rouge})} \label{stages:module}

\item  Une {\it stratégie générique}  est codée  à travers  \posl{}, en utilisant les  opérateurs fournis par le langage appliqués  sur des \new{\ms{} \textit{abstraite} qui représentent les \textit{signatures} des} composants donnés lors l'étape \ref{stages:module}, pour créer \ass. Cette  stratégie   définie  non  seulement  les informations   échangées,  mais   détermine  également   l'exécution parallèle de  composants. Lors  de cette  étape, les  informations à partager sont  transmises via  les opérateurs  ad-hoc. On  peut voir cette étape comme la définition de la colonne vertébrale des solveurs (figure \ref{subfig:as}).

\item  Les solveurs sont créés en instanciant \new{l'\as, par \oms{} et \opch}. %puis en les assemblant 

\item \new{Les solveurs sont assemblés en utilisant les opérateurs de communication fournis par le langage, pour creér des strategies de communication. Cet entité final s'appelle \INTROsoset{} (figure \ref{subfig:comm}).}
\end{enumerate}

\begin{figure}
	\centering
	\subfloat[][Definition du \ms{} et l'\opchs{}]{
		\label{subfig:modules}
		\includegraphics[width=0.5\columnwidth]{modules_1}
	}\\
	\subfloat[][Definition de l'\as]{%
		\label{subfig:as}
		\includegraphics[width=0.9\columnwidth]{as_1}
	}\\
	\subfloat[][Definition de la strategie de communication]{
		\label{subfig:comm}
		\includegraphics[width=0.9\columnwidth]{conn_1}
	}
	\caption[]{Construire des solveurs parallèles avec \posl{}}
	\label{fig:posl}
\end{figure}%fr

Les sous-sections suivantes expliquent en détail chacune des étapes ci-dessus.

\subsection{Computation module}

Un \om{}  est la plus basique  et abstraite manière de  définir un composant de calcul. Il reçoit une entrée, exécute un algorithme interne et retourne une sortie. Dans ce papier, nous utilisons ce concept afin de décrire et  définir les composants de base d'un  solveur, qui seront assemblés par l'\as.  

Un \om{} représente un  morceau de l'algorithme  du solveur  qui est susceptible de changer au cours de  l'exécution.   Il  peut  être
dynamiquement remplacé  ou combiné avec d'autres  \oms, puisque les \oms{}  sont  également  des   informations  échangeables  entre  les
solveurs. De  cette manière,  le  solveur  peut changer/adapter  son comportement à  chaud, en combinant  ses \oms{} avec ceux  des autres solveurs. Ils sont  représentés par  des blocs  bleus dans  la figure~\ref{fig:posl}.

\begin{definition}\label{def:module} \textbf{(Computation Module)}
Un \om{} $\mathcal{O}m$ est une application définie par :
\begin{equation}
 \mathcal{C}m:\mathcal{I} \rightarrow \mathcal{O}
\end{equation}
\end{definition}

Dans (\ref{def:module}),  la nature de $\mathcal{D}$  et $\mathcal{I}$ dépend du type de \om{}.  Ils peuvent être soit une configuration, ou  un  ensemble de  configurations, ou un ensemble de  valeurs  de différents types de données, etc.

Soit une méta-heuristique de recherche locale, basée sur un algorithme bien connu, comme par exemple {\it Tabu Search}. Prenons l'exemple d'un  \om{} retournant  le voisinage  d'une configuration  donnée, pour une certaine métrique de voisinage. Cet \om{} peut être défini par la fonction suivante:

\begin{equation}
\mathcal{C}m:D_1\times D_2\times\dots\times D_n \rightarrow 2^{D_1\times D_2\times\dots\times D_n}
\end{equation}

où $D_i$  représente  la  définition  des  domaines  de  chacune  des variables de la configuration d'entrée.

\subsection{Communication module}

Les \opchs{} sont  les composants des solveurs en charge  de la réception des informations  communiquées entre  solveurs. Ils  peuvent interagir
avec les  \oms, en fonction de l'\as. Les \opchs{} jouent  le rôle de prise, permettant aux  solveurs de  se  brancher et  de recevoir  des informations. Il sont représentés en rouge dans la figure~\ref{subfig:modules}.

Un \opch{} peut recevoir deux types d'informations, provenant toujours d'un solveur tiers : des données et des \oms. En  ce qui concerne les \oms, leur  communication peut  se faire  via la  transmission d'identifiants permettant à chaque solveur de les instancier.

Pour faire  la distinction entre  les deux différents types  de \opchs, nous appelons \INTROdopch{} les \opchs{} responsables de la réception de données  et \INTROoopch{} ceux s'occupant de la réception et de l'instanciation de \oms.

\defname{Data communication module}{
Un \dopch{} $\mathcal{C}h$ est un composant produisant une application définie comme suit : 
\begin{equation}
\label{def:dopench}
\mathcal{C}h: I\times\left\{D\cup\left\{NULL\right\}\right\} \rightarrow D \cup \left\{NULL\right\}
\end{equation}
et retournant l'information  $\mathcal{I}$ provenant d'un solveur tiers,quelque soit l'entrée $\mathcal{U}$.
}

\begin{definition}\label{def:oopench} \textbf{(Object communication module)} 
Si nous notons $\mathbf{M}$ l'espace  de  tous  les \oms{} de la définition~\ref{def:module}, alors un \oopch{} $\mathcal{C}h$ est  un composant produisant un \om{}  venant d'un solveur tiers défini ainsi :
\begin{equation}
\mathcal{C}h:I\times\left\{\mathbf{M}\cup\left\{NULL\right\}\right\} \rightarrow O\cup\left\{NULL\right\}
\end{equation}
\end{definition}

Puisque les \opchs{}  reçoivent  des  informations  provenant  d'autres solveurs sans pour autant avoir de contrôle sur celles-ci, il est  nécessaire  de  définir   l'information  {\it  NULL},  signifiant l'absence  d'information.  La  figure~\ref{fig:ochperform}  montre  le mécanisme interne d'un  \opch{}. Si un \dopch{} reçoit une  information,  celle-ci   est  automatiquement  retournée  (figure~\ref{subfig:doch},  lignes bleues).  Si un  \oopch{} reçoit un \om{}, ce dernier est instancié et exécuté avec l'entrée de l'\opch, et  le résultat  est retourné  (figure \ref{subfig:ooch}, lignes bleues). Dans les deux  cas, si aucune information n'est reçue, l'\opch{}  retourne l'objet  {\it NULL}  (figure \ref{fig:ochperform}, lignes rouges).

\begin{figure}
	\centering
	\subfloat[][Data \opch]{
		\label{subfig:doch}
		\includegraphics[width=0.7\linewidth]{D_OCh} %[width=0.2\textwidth]{muta1}
	}
	\\%\hspace{0.05\textwidth}%
	\subfloat[][Object \opch]{%
		\label{subfig:ooch}
		\includegraphics[width=0.7\linewidth]{O_OCh}%[width=0.2\textwidth]{muta2}
	}
	\caption[]{Mécanisme interne du \opch}
	\label{fig:ochperform}
\end{figure}%fr

\subsection{Abstract solver}

L'\as{}  est le c\oe{}ur du solveur. Il joint les \oms{} et les \opchs{} de  manière cohérente, tout en leur restant  indépendant. Ceci signifie  qu'elle peut  changer ou  être modifiée  durant l'exécution, sans altérer  l'algorithme général  et en  respectant la  structure du solveur.  À  travers  l'\as, on peut décider également des informations à envoyer aux autres solveurs. \new{Chaque fois que nous combinons certains composants en utilisant des opérateurs \posl{}, nous créons un \INTROm.}

\begin{definition}
\label{def:cm}
Noté par la lettre $\mathcal{M}$, un {\bf \m} est:
\begin{enumerate}\renewcommand{\labelitemi}{\scriptsize$\blacksquare$}
\item un \om{}; ou
\item un \opch{}; ou
\item $\left[\mbox{OP } \mathcal{M}\right]$, \new{la composition d'un module $\mathcal{M}$ exécuté sequentielement, en retournant une sortie, en dépendant de la nature de l'opérateur unaire \emph{OP};} ou \label{subdef:seq_uni}
\item $\left[\mathcal{M}_1 \mbox{ OP } \mathcal{M}_2\right]$, \new{la composition de deux modules $\mathcal{M}_1$ et $\mathcal{M}_2$ exécuté séquentiellement, en retournant une sortie, en dépendant de la nature de l'opérateur binaire \emph{OP}.}\label{subdef:seq}
\item $\left[\mathcal{M}_1 \mbox{ OP } \mathcal{M}_2\right]$, \new{la composition de deux modules $\mathcal{M}_1$ et $\mathcal{M}_2$ exécuté, en retournant une sortie, en dépendant de la nature de l'opérateur binaire \emph{OP}. Ces deux opérateurs vont être exécutes en parallèle si et seulement si \emph{OP} support le parallélisme, ou il lance une exception en cas contraire.}\label{subdef:par}
\end{enumerate}
Nous notons par $\mathbf{M}$ l'espace des \ms, et nous appelons \cms{} à la composition de \ms{} présentés en \ref{subdef:seq_uni} \ref{subdef:seq}, et/ou \ref{subdef:par}.
\end{definition}

Pour illustrer la définition~\ref{def:cm}, la figure~\ref{fig:cm} montre graphiquement le concept de \cm.
\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{cm} %[width=0.2\textwidth]{muta1}
	\caption[]{Un \cm}
	\label{fig:cm}
\end{figure}%fr

Dans le  cas particulier  où un  des \cms{}  impliqués est  un \opch{}, chaque opérateur gère l'information {\it NULL} à sa manière.

Afin   de  grouper   des   modules,  nous   utiliserons  la   notation $\left|.\right|$ comme un groupe générique qui pourra être indifféremment interprété comme $[.]$ ou comme $\lbk . \rbk_p$.

Ensuite, les opérateurs fournis par \posl{} sont présentés. 

\underline{\bf Sequential Execution Operator}: \new{L'opération $\left|\mathcal{M}_1\poslop{\mapsto}\mathcal{M}_2\right|$ définit le \cm{} $\mathcal{M}_{seq}$ comme le résultat de l'exécution de $\mathcal{M}_1$ suivi de $\mathcal{M}_2$. C'est un exemple d'opérateur ne  supportant pas une exécution parallèle de ses \cms impliqués, puisque l'entrée du second \cm{} est la sortie du premier.}

\underline{\bf Conditional Execution Operator}: \new{L'opération $\left|\mathcal{M}_1\circled{?}_{<cond>}\mathcal{M}_2\right|$ définit le \cm{} $\mathcal{M}_{cond}$ le résultat de l'exécution en séquentiel de $\mathcal{M}_1$ si $<cond>$ es {\bf vrai} or $\mathcal{M}_2$, autrement.}

\underline{\bf Cyclic Execution Operator}: \new{L'opération $\left|\circlearrowleft_{<cond>}\mathcal{M}\right|$ définit le \cm{} $\mathcal{M}_{cyc}$ en répétant séquentiellement l'exécution de $\mathcal{M}$ tant que $<cond>$ est {\bf vrai}.}

\underline{\bf Random Choice Operator}: \new{L'operation $\left|M_1\circled{$\rho$}\mathcal{M}_2\right|$ définit le \cm{} $\mathcal{M}_{rho}$ qui exécute $\mathcal{M}_1$ en suivant une probabilité $\rho$, ou en exécutant $\mathcal{M}_2$ en suivant une probabilité $(1-\rho)$.}

\underline{\bf Not {\it NULL}}: \new{L'operation $\left|\mathcal{M}_1\circled{$\vee$}\mathcal{M}_2\right|$ définit le \cm{} $\mathcal{M}_{non}$ qui exécute $\mathcal{M}_1$ et retourne une sortie si elle n'est pas {\it NULL}, ou exécute $\mathcal{M}_2$ et retourne une sortie autrement.}

\underline{\bf Minimum Operator}: \new{Soient $o_1$ et $o_2$ les sorties de $\mathcal{M}_1$ et $\mathcal{M}_2$, respectivement. Nous assumons qu'il existe un ordre total dans $I_1 \cup I_2$ où l'objet \emph{NULL} est la plus grand valeur. Alors, l'opération $\left|\mathcal{M}_1\circled{m}\mathcal{M}_2\right|$ définit le \cm{} $\mathcal{M}_{min}$ qui exécute $\mathcal{M}_1$ et $\mathcal{M}_2$, et retourne $\min\left\{o_1,o_2\right\}$.}

\underline{\bf Maximum Operator}: \new{Soient $o_1$ et $o_2$ les sorties de $\mathcal{M}_1$ et $\mathcal{M}_2$, respectivement. Nous assumons qu'il existe un ordre total dans $I_1 \cup I_2$ où l'objet \emph{NULL} est la plus petite valeur. Alors, l'opération $\left|\mathcal{M}_1\circled{M}\mathcal{M}_2\right|$ définit le \cm{} $\mathcal{M}_{max}$ qui exécute $\mathcal{M}_1$ et $\mathcal{M}_2$, et retourne $\max\left\{o_1,o_2\right\}$.}

\underline{\bf Race Operator}: \new{L'opération $\left|\mathcal{M}_1\circled{$\shortdownarrow$}\mathcal{M}_2\right|$ définit le \cm{} $\mathcal{M}_{race}$ qui exécute les deux \ms{} $\mathcal{M}_1$ et $\mathcal{M}_2$, et retourne la sortie du \m{} qui termine en premier}

Les opérateurs $\circled{$\rho$}$, $\circled{$\vee$}$ et $\circled{m}$ sont très  utiles en  terme de  partage d'informations entre   solveurs, mais également en terme de partage de comportements. Si un  des opérandes est un \opch{} alors l'opérateur peut recevoir le \om{} d'un autre solveur, donnant la possibilité d'instancier ce module dans le solveur le réceptionnant. L'opérateur va soit instancier le module s'il  n'est pas {\it NULL} et l'exécuter, soit exécuter le module donné par le second opérande.

Maintenant, nous présentons les opérateurs nous permettant d'envoyer de l'information vers d'autres solveurs. Deux types d'envois sont possibles :
\begin{inparaenum}[i)]
	\item on exécute un \m{} et on envoie sa sortie,
	\item ou on envoie le \m{} lui-même.
\end{inparaenum}

\underline{\bf Sending Data Operator}: \new{L'opération $\left|\senddataop{\mathcal{M}}\right|$ définit le \cm{} $\mathcal{M}_{sendD}$ qui exécute le \m{} $\mathcal{M}$ puis envoie la sortie vers un \opch.}

\underline{\bf Sending Module Operator}: \new{L'opération $\left|\sendmoduleop{\mathcal{M}}\right|$ définit le \cm{} $\mathcal{M}_{sendM}$ qui exécute le \m{} $\mathcal{M}$, puis envoie le \m{} lui même  vers un \opch.}

Avec  les opérateurs  présentés jusqu'ici, nous sommes  en mesure  de concevoir les \ass{} (ou algorithme) de résolution d'un problème de contraintes. Une fois un tel \as{} définie, on peut changer les composants (\oms{} et \opchs) auxquels elle fait appel, permettant ainsi d'implémenter différents solveurs à partir du même \as{} mais composés de différents \ms, du moment que ces derniers respectent la signature attendue, à savoir le types des entrées et sorties.

\new{Un \as{} est déclaré comme suit: après déclarer les noms de l'\mbox{\tet{\bf \as}} ({\it name}), la première ligne définit la liste des \oms{} abstraites ($\mathcal{L}^m$), la seconde ligne, la liste des \opchs{} abstraites ($\mathbf{M}$), puis l'algorithme du solver est définit comment le corps su solver (the root \cm{} $\mathbf{M}$), entre \mbox{\tet{\bf begin}} et \mbox{\tet{\bf end}}.}

\new{Un \as{} peut être déclaré par l'expression régulière suivante:}

\begin{center}
\tet{\bf abstract solver} {\it name} \tet{\bf computation}: $\mathcal{L}^m$ (\tet{\bf communication}: $\mathcal{L}^c$)? \tet{\bf begin} $\mathbf{M}$ \tet{\bf end}
\end{center}

Par exemple, l'algorithme~\ref{algo:as_example} montre l'\as{} correspondant a la figure~\ref{subfig:as}.

\begin{algorithm}[h]
\dontprintsemicolon
\SetNoline
\SetKwProg{myproc}{}{}{}
\myproc{\tet{\bf abstract solver} as\_01\;
\tet{\bf computation} : $I, V, S, A$ \; 
\tet{\bf connection}: $C.M.$}{
	\Begin{
		$I \poslop{\mapsto}$\\
		\While{$\left(\textbf{\Iter < } K_1\right)$}{
			$\left[V\poslop{\mapsto}S\poslop{\mapsto}\left[C.M.\poslop{m} \senddataop{A}\right]\right]$%
		}
	}
}
\caption{Pseudo-code \posl{} pour l'\as{} de la figure~\ref{subfig:as}}\label{algo:as_example}
\end{algorithm}

\subsection{Créer les solveurs}

\new{Maintenant on peut créer les solveurs en instanciant les \ms. Il est possible de faire ceci en spécifiant que un \mbox{\tet{\bf solver}} donné doit implémenter (en utilisant le mot clé \mbox{\tet{\bf implements}}) un \as{} donné, suivi par la liste de \omprefix{} puis \opchs{}. Ces \ms{} doivent correspondre avec les signatures exigé par l'\as.}

\begin{algorithm}[h]
\dontprintsemicolon
\SetNoline
\SetKwProg{myproc}{}{}{}
\tet{\bf solver} solver\_01 \tet{\bf implements} as\_01\;
\tet{\bf computation} : $I_{rand}, V_{1ch}, S_{best}, A_{AI}$ \; 
\tet{\bf connection}: $CM_{last}$\;
\caption{Une instanciation de l'\as{} présenté dans l'algorithme~\ref{algo:as_example}}\label{algo:solver_def}
\end{algorithm}

\subsection{Connecter les solveurs : créer le \soset}

\new{La dernière étape est connecter les solveurs entre eux. \posl{} fournit des outils pour créer des stratégies de communication très facilement. L'ensemble des solveurs connectés qui seront exécutés en parallèle pour résoudre un CSP s'appelle \INTROsoset{}.}

Les communications sont établies en respectant les règles suivantes :
\begin{enumerate}
\item  À chaque  fois qu'un  solveur  envoie une  information via  les opérateurs  $\llparenthesis .\rrparenthesis^{d}$  ou $\llparenthesis   .\rrparenthesis^{m}$, il créé une {\it prise mâle de communication} 
\item À  chaque fois qu'un  solveur contient  un \opch{}, il  créé une {\it prise femelle de communication} 
\item Les solveurs peuvent être connectés entre eux en reliant {\it prises mâles} et {\it femelles}.
\end{enumerate}

Avec l'opérateur~$(\cdot)$, nous  pouvons  avoir  accès aux  \oms{} envoyant une information et aux noms des \opchs d'un solveur. Par exemple : $Solver_1\cdot\mathcal{M}_1$ fournit  un accès à le \om{} $\mathcal{M}_1$ du $Solver_1$ si et seulement s'il est utilisé par l'opérateur  $\llparenthesis .\rrparenthesis^{d}$  (ou $\llparenthesis.\rrparenthesis^{m}$), et $Solver_2\cdot\mathcal{C}h_2$ fournit un accès au \opch{} $\mathcal{C}h_2$ de $Solver_2$.

Maintenant, nous définissons les opérateurs de communication que \posl{} fournit.

\begin{definition}\label{op_conn:1to1}
{\bf Connection One-to-One Operator} Soient
\begin{enumerate}
\item $\mathcal{J} = \left[\mathcal{S}_0\cdot \mathcal{M}_0, \mathcal{S}_1\cdot \mathcal{M}_1,\dots, \mathcal{S}_{N-1}\cdot \mathcal{M}_{N-1}\right]$ une liste de  {\it prises mâles}, et
\item $\mathcal{O} = \left[\mathcal{Z}_0\cdot \mathcal{CM}_0, \mathcal{Z}_1\cdot \mathcal{CM}_1,\dots, \mathcal{Z}_{N-1}\cdot \mathcal{CM}_{N-1}\right]$ une liste de {\it prises femelles}
\end{enumerate} Alors, l'opération
\[
\mathcal{J} \poslop{\rightarrow} \mathcal{O}
\]
\new{connecte chaque {\it prise mâles} $\mathcal{S}_i\cdot \mathcal{M}_i \in \mathcal{J}$ avec la correspondante {\it prise femelle} $\mathcal{Z}_i\cdot \mathcal{CM}_i \in \mathcal{O}$, $\forall\textbf{ }0 \leq i \leq N-1$ (voir figure~\ref{subfig:comm_simple}).}
\end{definition}

\begin{definition}\label{op_conn:1ton}
{\bf Connection One-to-N Operator} Soient 
\begin{enumerate} 
\item $\mathcal{J} = \left[\mathcal{S}_0\cdot \mathcal{M}_0, \mathcal{S}_1\cdot \mathcal{M}_1,\dots, \mathcal{S}_{N-1}\cdot \mathcal{M}_{N-1}\right]$ une liste de  {\it prises mâles}, et
\item $\mathcal{O} = \left[\mathcal{Z}_0\cdot \mathcal{CM}_0, \mathcal{Z}_1\cdot \mathcal{CM}_1,\dots, \mathcal{Z}_{M-1}\cdot \mathcal{CM}_{M-1}\right]$ une liste de {\it prises femelles}
\end{enumerate} Alors, l'opération
\[
\mathcal{J} \poslop{\rightsquigarrow} \mathcal{O}
\]
\new{connecte chaque {\it prise mâles} $\mathcal{S}_i\cdot \mathcal{M}_i \in \mathcal{J}$ avec chaque {\it prise femelle} $\mathcal{Z}_j\cdot \mathcal{CM}_j \in \mathcal{O}$, $\forall\textbf{ }0 \leq i \leq N-1$ et $0 \leq j \leq M-1$ (see Figure~\ref{subfig:comm_diff}).}
\end{definition}


\posl{} permet aussi de déclarer des solveurs non communicatifs pour les exécuter en parallèle, en déclarant seulement la liste des noms:
\[
\left[\mathcal{S}_0, \mathcal{S}_1, \dots, \mathcal{S}_{N-1}\right]
\]

\begin{figure}[h]
\centering
\subfloat[][Communication 1 à 1]{
	\label{subfig:comm_simple}
	\includegraphics[width=0.4\columnwidth]{comm_11.png}
}
\hspace{0.05\textwidth}%
\subfloat[][Communication 1 à N]{%
	\label{subfig:comm_diff}
	\includegraphics[width=0.4\columnwidth]{comm_1n.png}
}
\caption[]{Représentation graphique des opérateurs de communication}
\label{fig:comm}
\end{figure}



























































\section{Les résultats}

Le but principal de cette section est de sélectionner quelques instances de problèmes de référence, pour analyser et illustrer la versatilité de \posl{} pour étudier des stratégies de solution basées sur la recherche locale méta-heuristique avec communication. Grâce à \posl{} nous pouvons analyser des résultats et formuler des conclusions sur le comportement de la stratégie de recherche, mais aussi sur la structure de l'espace de recherche du problème. Dans cette section, nous expliquons la structure des  solveurs de \posl{} que nous avons générés pour les expériences, et les résultats.

Nous avons choisi l'une des méthodes de solutions les plus classique pour des problèmes combinatoires: l'algorithme méta-heuristique de recherche locale. Ces algorithmes ont une structure commune: ils commencent par l'initialisation des structures de données. Ensuite, une configuration initiale $s$ est générée. Après cela, une nouvelle configuration $s'$ est sélectionnée dans le voisinage $V \left(s \right) $. Si $s'$ est une solution pour le problème $P$, alors le processus s'arrête, et $s'$ est renvoyée. Dans le cas contraire, les structures de données sont mises à jour, et $s'$ est acceptée, ou non, pour l'itération suivante, en fonction de certains critères (par exemple, en pénalisant les caractéristiques des optimums locaux).

Les expériences ont été effectuées sur un processeur Intel \R{} Xeon \TM{} E5-2680 v2, 10 $\times$ 4 c\oe urs, 2.80GHz. Les résultats montrés dans cette section sont les moyennes de 30 runs pour chaque configuration. Dans les tableaux de résultats, les colonnes marquées {\bf T} correspondent au temps de l'exécution en secondes et les colonnes marquées {\bf It.} correspondent au nombre d'itérations. Toutes les expériences de cette section sont basées sur différentes stratégies en parallèle, avec 40 c\oe urs.

\subsection{Social Golfers Problem}

Le problème de \sg{} (\SGP) consiste à planifier $n = g \times p$ golfeurs en $g$ groupes de $p$ joueurs chaque semaine pendant $w$ semaines, de telle manière que deux joueurs jouent dans le même groupe au plus une fois. Une instance de ce problème peut être représentée par le triplet $g-p-w$. Ce problème, et d'autres problèmes étroitement liés, trouvent de nombreuses applications pratiques telles que le codage, le cryptage et les problèmes couvrants. Sa structure nous a semblé intéressante car elle est similaire à d'autres problèmes, comme {\it Kirkman's Schoolgirl} et {\it Steiner Triple System}, donc nous pouvons construire des modules efficaces pour résoudre un grand éventail de problèmes.

Nous avons utilisé uns stratégie de communication cyclique pour résoudre ce problème, en échangeant la configuration courante entre deux solveurs avec des caractéristiques différentes. Les résultats montrent que cette stratégie marche très bien pour ce problème.

\begin{algorithm}
\dontprintsemicolon
\scriptsize
\SetNoline
\SetKwProg{myproc}{\tet{\bf abstract solver}}{\tet{\bf begin}}{\tet{\bf end}}
\myproc{as\_eager \tcp*{{\sc Itr} $\rightarrow$ nombre d'itérations}
	\tet{\bf computation} : $I, V, S_1, S_2, A$\;\tcp*{{\sc Sci} $\rightarrow$ nombre d'itérations avec le même coût}}{%
	$I \poslop{\mapsto}$\\
	\While{$\left(\textbf{\Iter} < K_1\right)$}{
		$V \poslop{\mapsto} \left[S_1 \poslopcond{\Sci \% K_2} S_2\right] \poslop{\mapsto} A$		
	}
}
\tet{\bf solver} \solverposl{eager} \tet{\bf implements} as\_eager\;
\algoindent \tet{\bf computation} : $I_{BP}, V_{BAS}, S_{first}, S_{rand}, A_{AI}$ \;
\caption{Solveur pour \SGP}\label{as:golfers_eager}
\end{algorithm}

L'algorithme~\ref{as:golfers_eager} montre l'\as{} utilisé pour résoudre me manière séquentielle le \SGP{}. L'utilisation de deux \ms{} de sélection ($S_1$ et $S_2$) est un simple chamanisme pour éviter les minimums locaux: il tente d'améliorer le coût un certain nombre de fois, en exécutant le \om{} $S_1$. S'il n'y arrive pas, il exécute le \om{} $S_2$. L'\as{} a été instancié par les \oms{} suivantes:

\begin{enumerate}
\item $S_{BP}$ génère une configuration aléatoire $s$, en respectant la structure du problème, c'est-à-dire que la configuration est un ensemble de $w$ permutations du vecteur $[1..n]$.
\item $V_{BAS}$ définit le voisinage $V \left(s\right)$ permutant le joueur qui a contribué le plus au coût, avec d'autres joueurs dans la même semaine.
\item $S_{rirst}$ sélectionne la première configuration $s'\in V\left (s\right)$ qui améliore le coût actuel, et retourne $(s, s')$
\item $S_{rand}$ sélectionne une configuration aléatoire $s'\in V\left(s\right)$, et retourne $(s, s')$
\item $A_{AI}$ retourne toujours la configuration sélectionnée ($s'$).
\end{enumerate}

Pour \SGP{}, nous avons utilisé une stratégie de communication, où un solveur "compagnon", incapable de trouver une solution au final, mais capable de trouver des configurations avec an coût considérablement plus petit que ceci trouvé par le solveur \textit{standard} dans le même instant de temps, au début de la recherche. L'idée c'est d'échanger leurs configurations cycliquement, jusqu'à trouver une solution. Les algorithmes~\ref{as:golfers_full} et \ref{as:golfers_partial} montrent les solveurs utilisés pour cette stratégie, ou $V_{BP}(p)$ est le \om{} de voisinage pour le solveur "compagnon", qui cherche des configurations seulement changeant des joueurs parmi $p$ semaines. Le \opch{} instancié $CM_{last}$, prend en compte la dernière configuration reçue quand il est au moment de l'exécution.

\begin{algorithm}
\dontprintsemicolon
\scriptsize
\SetNoline
\SetKwProg{myproc}{\tet{\bf abstract solver}}{\tet{\bf begin}}{\tet{\bf end}}
\myproc{as\_standard \; %\hspace{3pt}
	\tet{\bf computation} : $I, V, S_1, S_2, A$ \; %\hspace{3pt}
	\tet{\bf communication} : $C.M.$\;}{%
	$I \poslop{\mapsto}$\\
	\While{$\left(\textbf{\Iter} < K_1\right)$}{
		$V \poslop{\mapsto} \left[S_1 \poslopcond{\Sci \% K_2} S_2\right] \poslop{\mapsto} \left[C.M. \poslop{m} \llparenthesis A \rrparenthesis^d\right]$		
	}
}
\tet{\bf solver} \solverposl{standard} \tet{\bf implements} as\_standard\;
\algoindent \tet{\bf computation} : $I_{BP}, V_{BAS}, S_{first}, S_{rand}, A_{AI}$ \;
\algoindent \tet{\bf communication} : $CM_{last}$ \;
\caption{Solveur standard pour \SGP}\label{as:golfers_full}
\end{algorithm}

\begin{algorithm}
\dontprintsemicolon
\scriptsize
\SetNoline
\SetKwProg{myproc}{\tet{\bf abstract solver}}{\tet{\bf begin}}{\tet{\bf end}}
\myproc{as\_compagnon \; %\hspace{1pt}
	\tet{\bf computation} : $I, V, S_1, S_2, A$ \;
	\tet{\bf communication} : $C.M.$\;}{
	$I \poslop{\mapsto}$\\
	\While{$\left(\textbf{\Iter} < K_1\right)$}{
		$V \poslop{\mapsto} \left[S_1 \poslopcond{\Sci \% K_2} S_2\right] \poslop{\mapsto} \left[C.M. \poslop{\vee} \llparenthesis A \rrparenthesis^d\right]$		
	}
}
\tet{\bf solver} \solverposl{compagnonandard} \tet{\bf implements} as\_compagnon\;
\algoindent \tet{\bf computation} : $I_{BP}, V_{BP}(p), S_{first}, S_{rand}, A_{AI}$ \;
\algoindent \tet{\bf communication} : $CM_{last}$ \;
\caption{Solveur compagnon pour \SGP}\label{as:golfers_partial}
\end{algorithm}

Nous avons dessiné aussi des différentes stratégies de communication, en combinant des solveurs connectés et non-connectés, et en appliquant des différents opérateurs de communication : \oneTone{} et \oneTn.

\begin{table}[t]
\centering
\renewcommand{\arraystretch}{1}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{p{1.4cm}|R{1cm}R{1cm}|R{1cm}R{1cm}|R{1.3cm}R{1.3cm}}
\hline
{\bf Instance} & \multicolumn{2}{c|}{\textbf{Séquentielle}} & \multicolumn{2}{c|}{\textbf{Parallèle}} & \multicolumn{2}{c}{\textbf{Coopérative}}\\
\cline{2-7}
 & T & It. & T & It. & T & It.\\
\hline
%\hline
5--3--7 & 1.25 & 2,903 & 0.23 & 144 & \good{0.10} & 98\\
8--4--7 & 0.60 & 338 & 0.28 & 93 & \good{0.14} & 54\\
9--4--8 & 1.04 & 346 & 0.59 & 139 & \good{0.36} & 146\\
\hline
\end{tabular}
}
\caption{Résultats pour \SGP}
\label{tab:golfers_seqpar}
\end{table}

Comme nous nous attendions, le tableau~\ref{tab:golfers_seqpar} confirme le succès de l'approche parallèle sur le séquentielle. Plus intéressante, les expériences confirment que la stratégie de communication proposée pour cet benchmark est la correcte: en comparant par rapport aux runs en parallèle sans communication, il améliore les runtimes par un facteur de 1.98 (facteur moyen parmi les trois instances). Les résultats coopératifs de ce tableau on été obtenus en utilisant l'opérateur de communication \oneTone{} avec 100\% de solveurs communicatifs. 


\subsection{Costas Array Problem}

Le problème \carr{} (\CARRP) consiste à trouver une matrice {\it Costas}, qui est une grille de $n \times n$ contenant $n$ marques avec exactement une marque par ligne et par colonne et les $n(n-1)/2 $ vecteurs reliant chaque couple de marques de cette grille doivent tous être différents. Ceci est un problème très complexe trouvant une application utile dans certains domaines comme le sonar et l'ingénierie de radar, et présente de nombreux problèmes mathématiques ouverts. Ce problème a aussi une caractéristique intéressante: même si son espace de recherche grandit factoriellement, à partir de l'ordre 17 le nombre de solutions diminue drastiquement.

Pour ce problème nous avons testé une stratégie de communication simple, où l'information a communiquer est la configuration courante. Pour construire les solveurs, nous avons réutilisé les \oms{} de sélection ($S_{first}$) et de d'acceptation ($S_{AI}$) et le \opch{} utilisés dans la résolution de \SGP{}. Les autres \oms{} sont les suivantes :

\begin{enumerate}
	\item $I_{perm}$: génère une configuration aléatoire $s$, comme une permutation du vecteur $[1..n]$. 
	\item $V_{AS}$: définit le voisinage $V \left(s\right)$ permutant la variable qui a contribué le plus au coût, avec d'autres.
\end{enumerate}

Pour résoudre \CARRP{} nous avons eu besoin d'utiliser un \om{} de \textit{reset} ($T_{AS}$) comme machinisme d'exploration. L'algorithme~\ref{as:costas} montre le solveur utilisé pour résoudre ce problème séquentiellement. Les résultats des runs en séquentiel et en parallèle sans communication sont montrés dans le tableau~\ref{tab:costas19}. Ils montrent le succès de l'approche en parallèle est montré encore une fois. Afin d'améliorer ces résultats, nous avons appliqué uns stratégies   simple de communication : communiquer la configuration courante au moment d'exécuter le critère d'acceptation. Les algorithmes~\ref{as:costas_sender} et~\ref{as:costas_receiver} montrent les solveurs envoyeur et récepteur.

\begin{algorithm}
\dontprintsemicolon
\scriptsize
\SetNoline
\SetKwProg{myproc}{\tet{\bf abstract solver}}{\tet{\bf begin}}{\tet{\bf end}}
\myproc{as\_hard \;
	\tet{\bf computation} : $I, T, V, S, A$\;}{
	$I \poslop{\mapsto}$\\
	\While{$\left(\textbf{\Iter} < K_1\right)$}{
		$T \poslop{\mapsto}$
		\whileinline{$\left(\textbf{\Iter \% } K_2\right)$}{$\left[V \poslop{\mapsto} S \poslop{\mapsto} A\right]$}
	}
}
\tet{\bf solver} \solverposl{1} \tet{\bf implements} as\_hard\;
\algoindent\tet{\bf computation} : $I_{perm}, T_{AS}, V_{AS}, S_{first}, A_{AI}$ \;
\caption{Solveur pour \CARRP}\label{as:costas}
\end{algorithm}

\begin{table}[t]
\captionsetup{belowskip=6pt,aboveskip=6pt}
\centering
\renewcommand{\arraystretch}{1}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{p{3.2cm}|R{1.2cm}R{1.5cm}R{1.5cm}}
	\hline
	{\bf STRATÉGIE} & T & It. & \% success\\
	\hline
	%\hline
	Séquentielle  & 132.73 & 2,332,088 & 40.00\\
	Parallèle & 25.51 & 231,262 & 100.00\\
	Coopérative & \good{10.83} & \good{79,551} & 100.00\\
	\hline
\end{tabular}
}
\caption{Résultats pour \CARRP{} 19}
\label{tab:costas19}
\end{table}

\begin{algorithm}
\dontprintsemicolon
\scriptsize
\SetNoline
\SetKwProg{myproc}{\tet{\bf abstract solver}}{\tet{\bf begin}}{\tet{\bf end}}
\myproc{as\_hard\_sen \; 
	\tet{\bf computation} : $I, T, V, S, A$\;}{
	$I \poslop{\mapsto}$\\
	\While{$\left(\textbf{\Iter} < K_1\right)$}{
		$T \poslop{\mapsto}$
		\whileinline{$\left(\textbf{\Iter \% } K_2\right)$}{$\left[V \poslop{\mapsto} S \poslop{\mapsto} \llparenthesis A \rrparenthesis^d\right]$}
	}
}
\tet{\bf solver} \solverposl{sender} \tet{\bf implements} as\_hard\_sen\;
\algoindent\tet{\bf computation} : $I_{perm}, T_{AS}, V_{AS}, S_{first}, A_{AI}$ \;
\caption{Solveur envoyeur pour \CARRP}\label{as:costas_sender}
\end{algorithm}

\begin{algorithm}
\dontprintsemicolon
\scriptsize
\SetInd{2pt}{2pt}
\SetNoline
\SetKwProg{myproc}{\tet{\bf abstract solver}}{\tet{\bf begin}}{\tet{\bf end}}
\myproc{as\_hard\_rec \; 
	\tet{\bf computation} : $I, T, V, S, A$ \; 
	\tet{\bf communication} : $C.M.$\;}{ 
	$I \poslop{\mapsto}$\\
	\While{$\left(\textbf{\Iter} < K_1\right)$}{
		$T \poslop{\mapsto}$
		\whileinline{$\left(\textbf{\Iter \% } K_2\right)$}{$\left[V \poslop{\mapsto} S \poslop{\mapsto} \left[A\poslop{m}C.M.\right]\right]$}
	}
}
\tet{\bf solver} \solverposl{receiver} \tet{\bf implements} as\_hard\_rec\;
\algoindent\tet{\bf computation} : $I_{perm}, T_{AS}, V_{AS}, S_{first}, A_{AI}$ \; 
\algoindent\tet{\bf communication}: $CM_{last}$\;
\caption{Solveur récepteur pour \CARRP}\label{as:costas-receiver}
\end{algorithm}

Un des buts principaux de cette étude a été d'explorer des différentes stratégies de communication. Nous avons ensuite mis en place et testé différentes variantes de la stratégie exposée ci-dessus en combinant deux opérateurs de communication (\oneTone{} et \oneTn) et des pourcentages différents de solveurs communicantes. Comme prévu, la meilleure stratégie était basée sur 100\% de communication avec l'opérateur \oneTn{}, parce que cette stratégie permet de communiquer un lieu prometteur à l'intérieur de l'espace de recherche à un maximum de solveurs, en refor\c{c}ant  l'intensification.

\subsection{Golomb Ruler Problem}

Le \grp{} (\GRP) consiste à trouver un vecteur ordonné de $n$ entiers non négatifs différents, appelés \textit{marques}, $m_1<\dots<m_n$, tel que toutes les différences $m_i- m_j$, $(i>j)$ sont toutes différentes. Une instance de ce problème est défini par le paire $(o,l)$ où $o$ est l'ordre du problème, (le nombre de \textit{marques}) et  $l$ est la longueur de la règle (la dernière {\it marque}). Nous supposons que la première \textit{marque} est toujours 0. Lorsque nous appliquons \posl{} pour résoudre une instance de problème séquentiellement, nous pouvons remarquer qu'il effectue de nombreux {\it restars} avant de trouver une solution. Pour cette raison, nous avons choisi ce problème pour étudier une stratégie de communication intéressante: communiquer la configuration actuelle afin d'éviter son voisinage, c'est à dire, une configuration {\it tabu}.

Nous réutilisons les \ms{} de sélection et d'acceptation des études antérieures ($S_{first}$ et$A_{AI}$) pour concevoir les \ass. Les nouvelles \ms{} sont:
\begin{enumerate}
\item $I_{sort}$: renvoie une configuration aléatoire $s$ en tant que vecteur d'entiers trié. La configuration est générée \textit{loin} de l'ensemble des configurations {\it tabu} arrivés via communication entre solveurs.
\item $V_{sort}$: donné une configuration, retourne le voisinage en changeant une valeur tout en gardant l'ordre, à savoir, le remplacement de la valeur $s_i$ par toutes les valeurs possibles $s'_i \in D_i$ en satisfaisant $s_{i-1}< s'_i < s_{i+1}$.
\end{enumerate}

Nous avons également ajouté un module de reset $T$: il reçoit et renvoie une configuration. Le \om{} utilisé pour l'instancier ($T_{tabu}$) insère la configuration reçue dans une liste \textit{tabu} à l'intérieur du solveur et retourne la configuration d'entrée \modified{tal cual}. L'algorithme~\ref{as:golomb_sender} présente le solveur utilisé pour envoyer des informations (solveur envoyeur).

\begin{algorithm}
\dontprintsemicolon
\scriptsize
\SetNoline
\SetKwProg{myproc}{\tet{\bf abstract solver}}{\tet{\bf begin}}{\tet{\bf end}}
\myproc{as\_golomb\_sender\;
	\tet{\bf computation} : $I, V, S, A, T$\;}{
	\While{$\left(\textbf{\Iter} < K_1\right)$}{
		$I \poslop{\mapsto}$ 
		\whileinline{$\left(\textbf{\Iter \% } K_2\right)$}{$\left[V \poslop{\mapsto} S \poslop{\mapsto} A\right]$} $\poslop{\mapsto} \llparenthesis T \rrparenthesis^d$
	}
}
\tet{\bf solver} \solverposl{sender} \tet{\bf implements} as\_golomb\_sender\;
\algoindent\tet{\bf computation} : $I_{sort}, V_{sort}, S_{first}, A_{AI}, , T_{tabu}$ \; 
\caption{Solveur envoyeur pour  \GRP}\label{as:golomb_sender}
\end{algorithm}

Le module $T_{tabu}$ est exécuté lorsque le solveur est incapable de trouver une meilleure configuration autour de l'actuelle: elle est supposée être un minimum local, et elle est envoyée au solveur récepteur. L'algorithme~\ref{as:golomb_receiver} présente solveur utilisé pour recevoir l'information. Le \opch{} $CM_{set}$ reçoit plusieurs configurations qui sont reçus par le \om{} $I_{sort}$ comme entrées.
 
\begin{algorithm}
\dontprintsemicolon
\scriptsize
\SetNoline
\SetKwProg{myproc}{\tet{\bf abstract solver}}{\tet{\bf begin}}{\tet{\bf end}}
\myproc{as\_golomb\_receiver\;
	\tet{\bf computation} : $I, V, S, A, T$\;
	\tet{\bf connection} : $C.M.$\;}{
	\While{$\left(\textbf{\Iter} < K_1\right)$}{
		$\left[C.M. \poslop{\mapsto} I \right] \poslop{\mapsto}$ \\
		\whileinline{$\left(\textbf{\Iter \% } K_2\right)$}{$\left[V \poslop{\mapsto} S \poslop{\mapsto} A\right]$} $\poslop{\mapsto} T$
	}
}
\tet{\bf solver} \solverposl{receiver} \tet{\bf implements} as\_golomb\_receiver\;
\algoindent\tet{\bf computation} : $I_{sort}, V_{sort}, S_{first}, A_{AI}, , T_{tabu}$ \; 
\algoindent\tet{\bf communication}: $CM_{set}$\;
\caption{Solveur récepteur pour \GRP}\label{as:golomb_receiver}
\end{algorithm}

Le bénéfice de l'approche en  parallèle avec \posl{} est aussi prouvé pour le \GRP{} (voir les tableaux~\ref{tab:golomb_seq} et~\ref{tab:golomb_seq}). Dans ces tableaux, la colonne \textbf{R} représente le nombre de redémarrages exécutées. Cette expérience a été réalisée en utilisant des solveurs similaires à ceux présentés précédemment, mais sans \opchs.

\begin{table}
\captionsetup{belowskip=6pt,aboveskip=6pt}
\centering 
\renewcommand{\arraystretch}{1}
%\resizebox{\columnwidth}{!}{%
\begin{tabular}{p{1.4cm}|R{1.1cm}R{1.3cm}R{0.6cm}R{1.5cm}}
\hline
{\bf Instance} & T & It. & R & \% success \\
\hline
%\hline
8--34 & 0.66 & 10,745 & 53 & 100.00 \\
10--55 & 67.89 & 446,913 & 297 & 88.00 \\
11--72 & 117.49 & 382,617 & 127 & 30.00 \\
\hline
\end{tabular}
%}
\caption{Résultats séquentielles pour \GRP{}}
\label{tab:golomb_seq}
\end{table}

\begin{table}
\captionsetup{belowskip=6pt,aboveskip=6pt}
\centering 
\renewcommand{\arraystretch}{1}
%\resizebox{\columnwidth}{!}{%
\begin{tabular}{p{1.4cm}|R{0.9cm}R{1.3cm}R{0.6cm}}
\hline 	
{\bf Instance} & T & It. & R \\
\hline
%\hline
8--34 & 0.43 & 349 & 1\\
10--55 & 4.92 & 20,504 & 13\\
11--72 & 85.02 & 155,251 & 51\\
\hline
\end{tabular}
%}
\caption{Résultats en parallèle non coopératifs pour \GRP{}}
\label{tab:golomb_par}
\end{table}

Pour \GRP, la stratégie de communication que nous adoptions a été différente. L'idée de cette stratégie est de profiter des nombreux redémarrages indiqués dans les tableaux~\ref{tab:golomb_seq} et~\ref{tab:golomb_par}. Chaque fois qu'un solveur redémarre, la configuration actuelle est communiquée pour alerter les solveurs et éviter son voisinage. De cette façon, chaque fois qu'un solveur redémarre, il génère une nouvelle configuration assez loin de ces "zones pénalisées".

Sur la base de l'opérateur de connexion utilisé dans la stratégie de communication, ce solveur peut recevoir une ou plusieurs configurations. Ces configurations sont l'entrée du \m{} de génération ($I_{sort}$). Ce module insère toutes les configurations reçues dans une liste {\it tabu}, puis il génère une nouvelle première configuration loin de toutes les configurations dans la liste {\it tabu}. 

Comme nous pouvons voir dans les tableaux~\ref{tab:golomb_comm_notab} et~\ref{tab:golomb_comm_tab} l'amélioration en temps d'exécution avec communication est plus visible quand on utilise l'opérateur de communication \oneTn{}, parce-que à chaque nouvelle itération, le solveur récepteur a plus d'information afin de générer une nouvelle configuration loin des "zones pénalisées".

\begin{table}[t]
\captionsetup{belowskip=6pt,aboveskip=6pt}
\centering 
\renewcommand{\arraystretch}{1}
\begin{tabular}{p{1.4cm}|R{0.9cm}R{1.2cm}R{0.8cm}}
	\hline 	
	{\bf Instance} & T & It. & R \\
	\hline
	8--34 & 0.44 & 309 & 1 \\
	10--55 & 3.90 & 15,437 & 10 \\
	11--72 & 85.43 & 156,211 & 52 \\
	\hline
\end{tabular}
\caption{Résultats avec communication sans liste tabu pour \GRP.}
\label{tab:golomb_comm_notab}
\end{table}

\begin{table}[t]
\captionsetup{belowskip=6pt,aboveskip=6pt}
\centering 
\renewcommand{\arraystretch}{1}
\begin{tabular}{p{1.4cm}|R{1cm}R{1.3cm}R{0.8cm}}
	\hline 	
	{\bf Instance} & T & It. & R \\
	\hline
	8--34 & \good{0.43} & 283 & 1\\
	10--55 & \good{3.16} & 12,605 & 8\\
	11--72 & \good{60.35} & 110,311 & 36\\
	\hline
\end{tabular}
\caption{Résultats avec communication avec liste tabu pour \GRP.}
\label{tab:golomb_comm_tab}
\end{table}

\section{Conclusions}

Dans cette thèse, nous avons  présenté \posl{}, un système pour construire des solveurs parallèles coopératifs. Il propose une manière modulable  pour créer   des  solveurs   capables   d'échanger   n'importe  quel   type d'informations, comme par exemple leur comportement même, en partageant
leurs \oms.  Avec \posl{},  de nombreux solveurs  différents pourront être créés et  lancés en parallèle, en utilisant  une unique stratégie générique mais en instanciant différents  \oms{} et \opchs{} pour chaque solveur. 

Il est possible d'implémenter différentes stratégies de communication, puisque  \posl{} fournit une couche pour définir les canaux de communication connectant les solveurs entre eux.

Nous avons présenté aussi des résultats en utilisant \posl{} pour résoudre des instances des problèmes classiques CSP. Il a été possible d'implémenter différentes stratégies communicatives et non communicatives, grâce au langage basé sur des opérateurs fournis, pour combiner différents \oms{}. \posl{} donne la possibilité de relier dynamiquement des solveurs, étant capable de définir des stratégies différentes en terme de pourcentage de solveurs communicatifs. Les résultats montrent la capacité de \posl{} à résoudre ces problèmes, en montrant en même temps que la communication peut jouer un rôle décisif dans le processus de recherche.

\posl{} a déjà une importante bibliothèque de \oms{} et de \opchs{} prête à utiliser, sur la base d'une étude approfondie sur les algorithmes méta-heuristiques classiques pour la résolution de problèmes combinatoires. Dans un avenir proche, nous prévoyons de la faire grandir, afin d'augmenter les capacités de \posl.

En même temps, nous prévoyons d'enrichir le langage en proposant de nouveaux opérateurs. Il est nécessaire, par exemple, d'améliorer le langage de {\it définition du solveur}, pour permettre la construction plus rapide et plus facile des ensembles de nombreux nouveaux solveurs. En plus, nous aimerions élargir le langage des opérateurs de communication, afin de créer des stratégies de communication polyvalentes et plus complexes, utiles pour étudier le comportement des solveurs.

\bibliography{biblio201608}

\end{document}
