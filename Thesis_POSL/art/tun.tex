Most of previously exposed methods to tackle combinatorial problems, involve a number of parameters that govern their behavior, and they need to be well adjusted. Most of the times they depend on the nature of the specific problem, so they require a previous analysis to study their behavior \cite{Birattari2005}. That is why another branch of the investigation arises: {\it parameter tuning}. It is also known as a meta optimization problem, because the main goal is to find the best solution (parameter configuration) for a program, which will try to find the best solution for some problem as well. In order to measure the quality of some found parameter setting for a program (solver), one of these criteria are taken into consideration: the speed of the run or the quality of the found solution for the problem that it solves. The selection of proper parameters for a particular algorithm is a quite complicate subject. This is the reason why many researchers are motivated to develop techniques to find good parameter settings automatically.

There exist tow classes to classify these methods: 
\begin{enumerate}
\item \textit{Off-line tuning}: Also known just as parameter tuning, were parameters are computed before the run, and
\item \textit{On-line tuning}: Also known as parameter control, were parameters are adjusted during the run.
\end{enumerate}

\subsection{Off-line tuning}

The technique of parameter tuning or off-line tuning, is used to compute the best parameter configuration for an algorithm before the run (solving a given instance of a problem), in order to obtain the best performance. The found parameters configuration does not change once the run is started. 

There exist some techniques to tune algorithms. The most common is the so called {\it racing procedure} which is based on a simple idea: sequentially evaluating candidates (parameter setups) on a series of benchmark instances and eliminate parameter configurations as soon as they are found too far behind the candidate with the overall best performance at a given stage of the race (\textit{incumbent}). A popular variant of this technique is the \textit{F-Race} method. It is also based on eliminating parameter configurations in some given steps. However, rather than just performing pairwise comparisons with the incumbent, it first uses the \textit{rank-based Friedman test}: for some independent randomly chosen variables, it assesses whether configurations in the race show no significant performance differences on some given instances. If there exist some configurations show better results than others, a series of pairwise tests between the incumbent and all other configurations is performed. All configurations found to have substantially worse results than the incumbent are removed from the race. The procedure is terminated either when only one configuration remains, or after a given timeout \cite{Hoos2012}. \etal{Eiben} present in \cite{A.E.Eiben2012} a study of this methods and their applications tuning Evolutionary Algorithms (EA).

{\sc Revac} is a method presented in \cite{Nannen2007} by \etal{Nannen}, based on information theory to measure parameter relevance, to calibrate parameters of EAs in a robust way. Instead of estimating the performance of an EA for different parameter values, the method estimates the expected performance when parameter values are chosen following a probability density distribution $C$. The method iteratively refines the probability distribution $C$ over possible parameter sets, and starting with a uniform distribution $C_0$ over the initial parameter space $\mathcal{X}$, the method gives a higher probability to regions of $\mathcal{X}$ that increase the expected performance of the target EA. In \cite{Smit2010} \etal{Smit} present a case study demonstrating that using {\sc Revac} the "world champion" EA (the winner of the CEC-2005 competition) can be improved with few effort.

In \cite{Riff2013}, \etal{Riff} present \textit{EVOCA}, a tool which allows meta-heuristics designers to obtain good parameter configuration with few effort. \textit{EVOCA} use an EA to find a good parameter setting for a meta-heuristic, and it is used as a step of the iterative design process. This tool allows designer to find parameter settings both for quantitative parameters (numerical values) and for qualitative parameters (e.g. crossover operators). Another tool for this end, but this time using local search methods to find the parameter setting is proposed by \etal{Hutter} in \cite{Hutter2009}. It has been applied with success in many combinatorial problems in order to find the best parameter configuration. {\sc ParamILS} It is an open source program written in {\it Ruby}, and the public source include some examples and a detailed and complete user guide with a compact explanation about how to use it with a specific solver \cite{Hutter2008}.

A different but interesting technique was successfully used to tune parameters for EAs through a model based on a {\it case-based reasoning} system. The work presented in \cite{Yeguas2014} by \etal{Yeguas} attempts to imitate the human behavior in solving problems: look in the memory how we have solved a similar problem.

\subsection{On-line tunning}

Although parameter tunning shows to be an effective way to adjust algorithms parameters, in some problems the optimal parameter settings may be different for various phases of the search process. This is the main motivation to use on-line tuning techniques to find the best parameter setting, also called \textit{parameter control techniques}. Parameter control techniques are divided into 
\begin{inparaenum}[i)]
\item \textit{deterministic parameter control}, where the value of a parameter is altered by some deterministic rule, ignoring any feedback; 
\item \textit{adaptive parameter control}, which continually update their parameters using feedback from the population or the search, and this feedback is used to determine the direction or magnitude of the parameter changes; and 
\item \textit{self-adaptive parameter control}, which assigns different parameters to each individual. Here, parameters to be adapted are coded into the chromosomes that undergo mutation and recombination
\end{inparaenum}\cite{Eiben1999}.

\etal{Drozdik} present in \cite{Drozdik} a study of various approaches to find out if one can find an inherently better one in terms of performance and whether the parameter control mechanisms can find favorable parameters in problems which can be successfully optimized only with a limited set of parameters. They focused in the most important parameters: 
\begin{inparaenum}[i)]
\item the \textit{scaling factor}, which controls the structure of new invidious; and
\item the \textit{crossover probability}.
\end{inparaenum}

Differential Evolution (DE) algorithm has been demonstrated to be an efficient and robust optimization method. However, its performance is very sensitive to the parameters setting, and this sensibility changes from a problem to another. \etal{Liu} propose in \cite{Liu2005} an adaptive approach which uses fuzzy logic controllers to guide the search parameters, with the novelty of changing the mutation control parameter and the crossover operator during the optimization process. \textit{SaDE} is a self-adaptive DE algorithm proposed by \etal{Qin} in \cite{Qin2009}, where both trial vector generation strategies and their associated control parameter values are gradually adjusted by learning from the way they have generated their previous promising solutions, eliminating this way the time-consuming exhaustive search for the most suitable parameter setting. This algorithm has been generalized by \etal{Huang} to multi-objective realm, with objective-wise learning strategies (\textit{OW-MOSaDE}) \cite{Huang2009}.

{\sc Meta-GAs} is a genetic self-adapting algorithm proposed by \etal{Clune}, adjusting operators of genetic algorithms. In this paper the authors propose an approach of moving towards a Genetic Algorithm that does not require a fixed and predefined parameter setting, because it evolves during the run \cite{Clune2005}.