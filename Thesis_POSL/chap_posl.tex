%----------------------------------------------------------------------------------------------
%------ POSL
%----------------------------------------------------------------------------------------------
\chapter{A Parallel-Oriented Language for Modeling Constraint-Based Solvers}
\label{chap:posl}
\textit{In this chapter we introduce \posl{} as our main contribution and a new way to solve \csps{}. We resume its characteristics and advantages, and we get into details in the next sections. We describe a general outline to follow in order to build parallel solvers using \posl, and following each step is described in details.}
\vfill
\minitoc
\newpage

In this chapter we present the different steps to follow to build communicating parallel solvers with \posl. 
First of all, the algorithm that we have conceived to solve the target problem is modeled by decomposing it into small modules of computation. After that, they are implemented as separated {\it functions}. We name them \oms{} (see Figure~\ref{subfig:modules}, blue shapes). The coder's experience is crucial to find a good decomposition of its algorithm, because it will have an important impact in its future reuse and variability. The next step is to decide what information is interesting to receive from other solvers. This information is encapsulated into another kind of component called \opch, allowing data transmission among solvers (see Figure~\ref{subfig:modules}, red shapes).
In a third stage, is to glue the modules through \posl{}'s inner language (the reader can see an example in Appendix \tet{[...]}) to create independent solvers.
The parallel-oriented language based on operators that \posl{} provides (see Figure~\ref{subfig:as}, green shapes) allows not only the information exchange, but also executing components in parallel. In this stage, the information that is interesting to share with other solvers, is sent using operators. After that, we can connect them using {\it communication operators}. We call this final entity a {\it solvers set} (see Figure~\ref{subfig:conn}).

\begin{figure}[h]
	\centering
	\subfloat[][Creating \posl's modules]{
		\label{subfig:modules}
		\includegraphics[width=0.4\linewidth]{modules.png}
	}\\
	\subfloat[][Assembling modules using \posl's operators]{%
		\label{subfig:as}
		\includegraphics[width=0.6\linewidth]{as.png}
	}\\
	\subfloat[][Connecting \posl{} solvers to create \comstrs]{%
		\label{subfig:conn}
		\includegraphics[width=0.6\linewidth]{conn.png}
	}
	\caption[]{Solver construction process using \posl}
	\label{fig:posl}
\end{figure}

Once the solvers set is ready, the last step is to model the problem to solve. To do so, the user must follow the framework specification to implement the benchmark, respecting some requirements. The most important one is to implement a {\it cost function} computing the cost for a given configuration, i.e., an integer indicating how much the configuration violates the set of constraints. This integer equals zero if the configuration is a solution.

\section{Modeling the target benchmark}
\label{sec:model}

\input{sect_model}

\section{First Stage: Creating \posl's modules}
\label{sec:1ststage}

\input{sect_1}

\section{Second Stage: Assembling \posl's modules}
\label{sec:2ndstage}

\input{sect_2}

\section{Third Stage: Creating \posl{} solvers}
\label{sec:3rdstage}

\input{sect_3}

\section{Forth Stage: Connecting the solvers}
\label{sec:4thstage}

\input{sect_4}

\section{Step-by-step \posl{} code example}

In this section we explain how to create a solver using \posl{} through an example. \posl{} creates solvers based on local search meta-heuristics algorithms. These algorithms have a common structure: \begin{inparaenum}[1.] \item they start by initializing some data structures (e.g. a \emph{tabu list} for \emph{Tabu Search}~\cite{Gendreau2010}, a \emph{temperature} for \emph{Simulated Annealing}~\cite{Nikolaev2010}, etc.). \item An initial configuration $s$ is generated. \item A new configuration $s'$ is selected from the neighborhood $\mathcal{V}\left(s\right)$. \item If $s'$ is a solution for the problem $P$, then the process stops, and $s'$ is returned. If not, the data structures are updated, and $s'$ is accepted or not for the next iteration, depending on some criterion.\end{inparaenum} An example of such data structure can be the penalizing features of local optima defined by Boussa√Ød et al~\cite{Boussaid2013} in their algorithm \emph{Guided Local Search}.

%Restarts are classic mechanisms to avoid becoming trapped in local minimum. They are trigged by reaching no improvements or a timeout.

{\it Abstract} \oms{} composing \emph{local search meta--heuristics} are the following:

\begin{list}{\boxed{Abstract\hspace{4pt}Computation\hspace{4pt}module- \arabic{qcounter}~}}{\usecounter{qcounter}} \itemsep0em 
	\item $I$: Generating a configuration $s$
	\item $V$: Defining the neighborhood $\mathcal{V}\left(s\right)$
	\item $S$: Selecting $s' \in \mathcal{V}\left(s\right)$
	\item $A$: Evaluating an acceptance criteria for $s'$
\end{list}

To be more specific in our example, we describe come concrete \oms{} that we can use:

\begin{list}{\boxed{Computation\hspace{4pt}module- \arabic{qcounter}~}}{\usecounter{qcounter}} \itemsep0em 
	\item $I_{rand}$: Generates a random configuration $s$ \label{estruct:S}
	\item $V_{1ch}$: Defines the neighborhood $\mathcal{V}\left(s\right)$ changing only one element \label{estruct:V}
	\item $S_{best}$: Selects the best configuration $s' \in \mathcal{V}\left(s\right)$ improving the current cost. \label{estruct:SS}
	\item $A_{a.i.}$: Evaluates an acceptance criteria for $s'$. We have chosen the classical module selecting the configuration with the lowest global cost, {\it i.e.}, the one which is likely the closest to a solution. \label{estruct:A}
\end{list}

\modified{We can combine modules to create more complex ones. For example, in the example we use in this section, we want to apply some selection criteria, but if there is not improvement in the current configuration, we select a configuration randomly. To do so, we use the operator~$\circled{?}$ to combine the \om{}~\ref{estruct:SS} with another:}

\begin{list}{\boxed{Computation\hspace{4pt}module-3. \arabic{qcounter}~}}{\usecounter{qcounter}} \itemsep0em  
	\item $S_{rand}$: Selects a random configuration $s' \in \mathcal{V}\left(s\right)$.
\end{list}

\modified{Let's make this solver a little bit more complex: in the time of applying the acceptance criteria, suppose that we want to receive a configuration from other solver, to compare it with ours and take it if its cost is lower. We can do that applying the operator~$\circled{m}$ to combine the \om{}~\ref{estruct:A} with a \opch:}

\begin{list}{\boxed{Communication\hspace{4pt}module- \arabic{qcounter}:~}}{\usecounter{qcounter}} \itemsep0em
	\item $C.M.$: Receiving a configuration.\label{struct:opch}
\end{list}

\modified{Figure~\ref{fig:as_ex} shows a graphic representation of the \as{} that we create for our example. In this Figure all the modules are abstract, so we can instantiate them afterwards to create concrete solvers. Note that we also want to send the output of the \om{} $A$, in order to share the current configuration with other solvers.}

\begin{figure}[h]
	\centering	
	\includegraphics[width=0.7\linewidth]{aexample.png}
	\caption{Graphic representation of an \as}\label{fig:as_ex}
\end{figure}

\modified{Algorithm \ref{algo:as_ex} shows the \posl{} pseudo-code for the \as{} described above, using predefined operators, and Algorithm~\ref{algo:cs_ex} shows the concrete solver definition using the concrete \omprefix{} and \opchs{} already presented. In the later, we have used the concrete \opch{} $CM_{last}$, that receives all the configuration sent to it, and selects the last arrived.}
%\af{} provides information regarding the execution process, such as number of {\sc Iterations}, solver execution {\sc Time}, {\sc Best} found solution, among others.

\begin{algorithm}[H]
\dontprintsemicolon
\SetNoline
\SetKwProg{myproc}{}{}{}
\myproc{\tet{\bf abstract solver} as\_example\;
\tet{\bf computation} : $I, V, S_1, S_2, A$ \; 
\tet{\bf connection}: $C.M.$}{
	\Begin{
		%\While{$($\Iter $< K_1)$}
		%{
			$I \sec$ \; %\circled{$\mapsto$}$\;
			\While{$($\Iter \% $K_2)$}{
				$\left[V \sec \left[S_1\textbf{  } \circled{$\vee$} \textbf{  } S_2\right]\right] \sec \left[\llparenthesis A\rrparenthesis^o \textbf{  } \circled{m} \textbf{  } C.M.\right] $\;
			}
		%}
	}
}
\caption{\posl{} pseudo-code for \as{} presented in Figure~\ref{fig:as_ex}}\label{algo:as_ex}
\end{algorithm}	

\begin{algorithm}[H]
\dontprintsemicolon
\SetNoline
\SetKwProg{myproc}{}{}{}
%\myproc{
\tet{\bf solver} solver\_example \tet{\bf implements} as\_example\;
\tet{\bf computation} : $I_{rand}, V_{1ch}, S_{best}, A_{a.i.}$ \; 
\tet{\bf connection}: $CM_{last}$\; %}{
%	\Begin{
%	}
%}
\caption{An instantiation of the \as{} in Algorithm~\ref{algo:as_ex}}\label{algo:cs_ex}
\end{algorithm}



%\noindent%
%%\begin{minipage}{\textwidth}
%%	\centering
%\begin{minipage}[t]{.52\textwidth}
%	\begin{algorithm}[H]
%		\caption{Local search meta--heuristic general strategy}
%		\dontprintsemicolon
%		\SetNoline
%		\SetKwProg{myproc}{}{}{}%\mathcal{M}_1^a, \mathcal{M}_1^b,
%		\myproc{$St \leftarrow$ \str \\ \om $: \mathcal{M}_1^a, \mathcal{M}_1^b, \mathcal{M}_2, \mathcal{M}_2, \mathcal{M}_4$ ;\\ \och $: \mathcal{C}h_1$ ;}{
%			\Begin{
%				\While{$($\Iter \% $10000$ $!$= $0)$}{%\mathcal{M}_1^a \circled{$\rho$} \mathcal{M}_1^b
%					$\left[\mathcal{M}_1^a \circled{$\rho$} \mathcal{M}_1^b\right] \longmapsto$\;
%					\While{$($\Iter \% $1000$ $!$= $0)$}{
%						$\left[\mathcal{C}h_1 \circled{$\vee$} \mathcal{M}_2\right] \longmapsto \mathcal{M}_3 \longmapsto \llparenthesis\mathcal{M}_4\rrparenthesis^o$\;
%					}
%				}
%			}
%		}
%		\label{algo:stLSM}
%	\end{algorithm}		
%\end{minipage}
%\hspace{.05\textwidth}
%\begin{minipage}[t]{.40\textwidth}
%	\begin{algorithm}[H]
%		\caption{Local search meta--heuristic solver definition}%
%		\dontprintsemicolon
%		\SetNoline
%		\SetKwProg{myproc}{}{}{}
%		\myproc{$\Sigma_1 \leftarrow$ \solver}{
%			\Begin{%
%				\Strategy{}{St}%
%				%			\oModule{}{$\mathcal{M}_1^a$, $\mathcal{M}_1^b$, $\mathcal{M}_2$, $\mathcal{M}_3$, $\mathcal{M}_4$}
%				\oModule{}{$m_1^a$, $m_1^b$, $m_2$, $m_3$, $m_4$}
%				\oChannel{}{$ch_1$}%
%			}%
%		}%
%		\label{algo:defLSM}%	
%	\end{algorithm}
%\end{minipage}
%%\captionof{figure}{Concrete strategies for Algorithm \ref{algo:mySA}}
%%\label{fig:strategies_sa}
%%\end{minipage}
%\vspace{0.3cm}
%
%Algorithm \ref{algo:defLSM} shows the solver definition. We place here the \cstr{}, followed by instances of the \m s (\module s and \opch s). The instances have to respect the type of the \m s declared in the \cstr.
%%Before declare which are the modules in the solver, it is necessary to instantiate them.
%
%\begin{algorithm} %[H]
%\dontprintsemicolon
%\SetNoline
%%\incmargin{1em}
%$\Sigma_2\cdot\mathcal{M}_{\mathcal{V}} \rightsquigarrow \Sigma_1\cdot\mathcal{C}h_1$
%\caption{Inter--solvers communication definition}%
%\label{algo:defCOMM}%
%\end{algorithm}
%
%Supposing that there exist another solver $\Sigma_2$ with an \module{} called $\mathcal{M}_{\mathcal{V}}$ sharing its neighborhood function, we can connect it with the solver $\Sigma_1$ as the Algorithm \ref{algo:defCOMM} shows.
