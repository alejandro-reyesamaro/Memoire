In this section \nqp{} (\NQP) is selected as a benchmark to study a \commstr{} consisting in exchanging cyclically the configuration between solvers using different neighborhood functions, in order to accelerate the process of generating very promising configurations. Final obtained results show that this \commstr{} works well for some instances of this problem.

\subsection{Problem definition}

The \nqp{} (\NQP) asks how to place $N$ queens on a chess board so that none of them can hit any other queen in one move. This problem was introduced in 1848 by the chess player Max Bezzelas as the \textit{8-queen problem}, and years latter it was generalized as \textit{N-queen problem} by Franz Nauck. Since then many mathematicians, including Gauss, have worked on this problem. \new{It can be directly applied to diverse fields, such as parallel memory storage schemes, traffic control, deadlock prevention, neural networks, constraint satisfaction problems, among others} \cite{Bell2009}. Some studies suggest that the number of solution grows exponentially with the number of queens ($N$), but local search methods have been shown very good results for this problem \cite{Sosic1994}. For that reason we tested some communication strategies using \posl{}, to solve a problem relatively easy to solve using non communication strategies.

\new{Benchmarks in this chapter were also modeled as unconstrained optimization problems. The proposed model for \NQP{} has $N$ variables: $\left\{v_1, v_2, \dots, v_N\right\}$. Their domains are the same: $D_{v_i}=\left\{1, \dots, N\right\}$.}

\new{The cost function for this benchmark was implemented in C++ based on the current implementation of Adaptive Search\footnote{It is based on the code from Daniel D\'{i}az available at \href{https://sourceforge.net/projects/adaptivesearch/}{https://sourceforge.net/projects/adaptivesearch/}}. It assumes that a configuration $s$ for this problem is an integer permutation of the set $\left\{1...N\right\}$, \ie $s_i = j$ (the $i^{th}$ variable has the value $j$) means that there is a queen placed in column $i$ and row $j$. In that sense, the cost function does not verify whether values in $s$ are all different.}

\new{Assuming this structure in the configuration, the cost function only has to check whether there are diagonal \textit{collisions} between queens. To do that two vectors $Err^{d1}$ and $Err^{d2}$ are created of size $2\cdot N-1$ (the number of diagonals in a $N\times N$ matrix) to store the number of queens placed on each diagonal. So, $Err^{d1}_{i+N-1-j}$ contains the number of queens on such diagonal, taking into account that $j$ is the position (row) of the queen placed on the column $i$, for all $i\in [1...N]$. Analogously, $Err^{d2}_{i+j}$ contains the number of queens on such diagonal (on the other direction). Based on this structure, the cost $c_s$ of a configuration is:} 

\begin{equation}\label{func:cost_nqp}
c_s=\sum_{d=1}^{2N-1}{\mathcal{F}(Err^{d1}_{d}) + \mathcal{F}(Err^{d2}_{d})}
\end{equation}

where:
\begin{equation*}
\mathcal{F}(x)=\left\{
\begin{tabular}{ll}
0 & $x \leq 1$ \\
x & otherwise
\end{tabular}
\right.
\end{equation*}

\subsection{Experiments design and results}

To handle this problem, some modules used for the \sgp{} have been reused: the selection \oms{} $S_{first}$ and $S_{best}$, and the acceptance \om{} $A_{AI}$. It uses a simple \as{} presented in Algorithm~\ref{as:nq}. \new{For this problem, \posl{} does not perform restarts, so the value $K_1$ was fixed in 15000 in order to be able to use the same \as{} for all instances}. 

\begin{algorithm}[H]
\dontprintsemicolon
\SetNoline
\SetKwProg{myproc}{\tet{\bf abstract solver}}{\tet{\bf begin}}{\tet{\bf end}}
\myproc{as\_simple \tcp*{{\sc Itr} $\rightarrow$ number of iterations}
	\tet{\bf computation} : $I, V, S, A$\;}{
	$I \poslop{\mapsto}$
		\whileinline{$\left(\textbf{\Iter < } K_1\right)$}{$ V \poslop{\mapsto} S \poslop{\mapsto} A$}	
}
\tet{\bf solver} \solverposl{as} \tet{\bf implements} as\_simple\;
\algoindent \tet{\bf computation} : $I_{perm}, V_{AS}, S_{first}, A_{AI}$ \;
\tet{\bf solver} \solverposl{selective} \tet{\bf implements} as\_simple\;
\algoindent \tet{\bf computation} : $I_{perm}, V_{PAS}(m), S_{first}, A_{AI}$ \; 
%\tet{\bf connection}: $CM_{last}$\;
\caption{\As{} for \NQP}\label{as:nq}
\end{algorithm}

Solvers used for the experiments without communications are presented in Algorithm~\ref{as:nq}, where the \as{} is instantiated by the solver \solverposl{as} with the neighborhood \om{} $V_{AS}$. Given a configuration, this module returns a neighborhood $V\left(s\right)$ swapping the variable which contributes the most to the cost, with all others. This solver was able to find solutions but taking too much time (a minute for 6000-queens, for example). For that reason a neighborhood \om{} $S_{PAS}(m)$ has been implemented similar to $S_{AS}$ but instead of generating neighbors swapping the most culprit variable with all others, it is swapped only with a percentage \new{$m$ of them}. Solver \solverposl{selective} instantiates the \as{} with this \om, showing much better results than \solverposl{as}.

Table~\ref{tab:nqueens_seqpar} presents results of sequential and parallel runs, using \solverposl{selective} with a tuned value of $m=2.5$. Results show that the improvement of the parallel scheme using \posl{} is not significant. While the number of solutions of this problem is only known for the very small value of $N = 27$, studies suggest that the number of solutions \new{grows significantly with $N$, \ie the number of new solutions is about 10 times bigger. It means that the complexity of the problem grows with its order, but not excessively. However, the number of new possible configurations is $N$ times bigger. It implies that as the problem grows in order, solutions inside the search space are farer away from each other. So, in a search space much bigger and with scattered solutions, the probability of starting the search close to a solution decreases, and, as we can deduce from results, it does not increase considerably when applying the parallel approach. This explains also the decrease in the standard deviation when $N$ increases: all solvers start the search from configurations ``similarly far'' from the solutions, so their courses tent to be similar.}

%it becomes easier to solve through local search methods. The behavior of \posl{} solving this problem matches  with this hypothesis: the search process solving larger instances is more stable and the convergence is direct. In a well spread search space with a lot of solutions, the parallelism using 40 cores do not provide a lot of improvement. In that sense, \modified{as a future work, experiments using \posl{} to solve \NQP{} in parallel with more cores are planned.}

\begin{table}[t]
\centering 
\renewcommand{\arraystretch}{1}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{p{1.3cm}|R{1.3cm}R{1.3cm}R{1.3cm}R{1.3cm}|R{1.3cm}R{1.3cm}R{1.3cm}R{1.3cm}}
	\hline %\noalign{\smallskip}	
	\multirow{2}{*}{\footnotesize{\centering {\bf Instance}}} & \multicolumn{4}{c|}{\bf Sequential} & \multicolumn{4}{c}{\bf Parallel} \\
	\cline{2-9}
	& T & T(sd) & It. & It.(sd) & T & T(sd) & It. & It.(sd) \\	
	\hline
	250 & 0.29 & 0.072 & 8,898 & 2,158 & 0.19 & 0.003 & 4,139 & 913 \\
	500 & 0.35 & 0.087 & 4,203 & 998 & 0.24 & 0.036 & 2,675 & 366 \\
	1000 & 0.35 & 0.126 & 2,766 & 445 & 0.30 & 0.037 & 2,102 & 222 \\
	3000 & 1.50 & 0.138 & 2,191 & 77 & 1.33 & 0.055 & 2,168 & 71 \\
	6000 & 4.71 & 0.183 & 3,339 & 51 & 4.57 & 0.123 & 3,323 & 43 \\
	\hline
\end{tabular}
}
\caption{Results for \NQP{} (sequential and parallel without communication)}\label{tab:nqueens_seqpar}
\end{table}

\separation

In order to test the cooperative approach with this problem, a first and simple experiment was performed. Using the previous defined \as{}, communicating solvers were built to create a simple \commstr{} in which the shared information is the current configuration, and is communicated in one direction (from sender solvers to receivers). Algorithms~\ref{as:nq_sender}~and~\ref{as:nq_receiver} show that the communication is performed while applying the acceptance criterion. We design different communication strategies: 
\begin{itemize}
\item a set of sender solvers sending information to receiver solvers, using operator \oneTone{} (see see Algorithm~\ref{comm:nqueens_simple_11}) and operator \oneTn{} (see Algorithm~\ref{comm:nqueens_simple_1nk} with $K=1$)
\item some sets of sender solvers sending information to receiver solvers, using operator \oneTn{} (see see Algorithm~\ref{comm:nqueens_simple_1nk}), with $K\in\left\{2, 4\right\}$
\end{itemize}

\begin{algorithm}[h]
\dontprintsemicolon
\SetNoline
\SetKwProg{myproc}{\tet{\bf abstract solver}}{\tet{\bf begin}}{\tet{\bf end}}
\myproc{as\_sender \tcp*{{\sc Itr} $\rightarrow$ number of iterations}
	\tet{\bf computation} : $I, V, S, A$\;}{
	$I \poslop{\mapsto}$
		\whileinline{$\left(\textbf{\Iter < } K_1\right)$}{$ V \poslop{\mapsto} S \poslop{\mapsto} \llparenthesis A \rrparenthesis^d$}	
}
\tet{\bf solver} \solverposl{sender} \tet{\bf implements} as\_sender\;
\algoindent \tet{\bf computation} : $I_{perm}, V_{PAS}(m), S_{first}, A_{AI}$ \;
\caption{Sender solver for \NQP{} (simple \commstr)}\label{as:nq_sender}
\end{algorithm}

\begin{algorithm}[h]
\dontprintsemicolon
\SetNoline
\SetKwProg{myproc}{\tet{\bf abstract solver}}{\tet{\bf begin}}{\tet{\bf end}}
\myproc{as\_receiver \tcp*{{\sc Itr} $\rightarrow$ number of iterations}
	\tet{\bf computation} : $I, V, S, A$\;
	\tet{\bf communication} : $C.M.$\;}{%
	$I \poslop{\mapsto}$
		\whileinline{$\left(\textbf{\Iter < } K_1\right)$}{$ V \poslop{\mapsto} S \poslop{\mapsto} \left[A \poslopcond{\Iter \% K_2} \left[A \poslop{m} C.M.\right]\right]$}
}
\tet{\bf solver} \solverposl{receiver} \tet{\bf implements} as\_receiver\;
\algoindent \tet{\bf computation} : $I_{perm}, V_{PAS}(m), S_{first}, A_{AI}$ \;
\algoindent \tet{\bf communication}: $CM_{last}$\;
\caption{Receiver solver for \NQP{} (simple \commstr)}\label{as:nq_receiver}
\end{algorithm}

\begin{algorithm}[H]
\dontprintsemicolon
\SetNoline
$\left[\eqsolverposl{sender}\posldot A\right] \onetoone \left[\eqsolverposl{receiver}\posldot C.M.\right]20;$
\caption{Simple \commstr{} \oneTone{} for \NQP}\label{comm:nqueens_simple_11}
\end{algorithm}

\begin{algorithm}[H]
\dontprintsemicolon
\SetNoline
$\left[\eqsolverposl{sender}\posldot A(\tfrac{20}{K})\right] \oneton \left[\eqsolverposl{receiver}\posldot C.M.(\tfrac{20}{K})\right]K;$
\caption{Simple \commstr{} \oneTn{} for \NQP}\label{comm:nqueens_simple_1nk}
\end{algorithm}

Tables~\ref{tab:nqueens_simplecomm11} and ~\ref{tab:nqueens_simplecomm1n} show that the communication improvement with respect to non communicating results in terms of runtime and iterations was not significant. In contrast to \SGP, \posl{} does not get trapped so often into local minima during the resolution of \NQP{}. For that reason, the shared information, once received and accepted by the receivers solvers, does not improve largely the current cost.

\begin{table}[t]
\centering 
\renewcommand{\arraystretch}{1}
\newcommand{\cwnq}{1.1cm}
\begin{tabular}{p{1.3cm}|R{\cwnq}R{\cwnq}R{\cwnq}R{\cwnq}}
	\hline 
	\multirow{2}{*}{\footnotesize{\centering {\bf Instance}}} & \multicolumn{4}{c}{\bf Communication 1-1} \\
	\cline{2-5}
	& T & T(sd) & It. & It.(sd) \\	
	\hline
	250 & 0.18 & 0.040 & 3,433 & 697 \\ 
	500 & 0.25 & 0.047 & 2,216 & 427 \\
	1000 & 0.26 & 0.056 & 1,735 & 424\\
	3000 & 1.21 & 0.088 & 1,873 & 227\\
	6000 & 4.38 & 0.111 & 3,178 & 121\\	
	\hline
\end{tabular}
\caption{Simple \commstr{} \oneTone{} for \NQP}\label{tab:nqueens_simplecomm11}
\end{table}

\begin{table}[t]
\centering 
\renewcommand{\arraystretch}{1}
\newcommand{\cwnq}{1.1cm}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{p{1.3cm}|R{\cwnq}R{\cwnq}R{\cwnq}R{\cwnq}|R{\cwnq}R{\cwnq}R{\cwnq}R{\cwnq}|R{\cwnq}R{\cwnq}R{\cwnq}R{\cwnq}}
	\hline %\noalign{\smallskip}	
	\multirow{2}{*}{\footnotesize{\centering {\bf Instance}}} & \multicolumn{4}{c|}{\bf Communication 1-n} & \multicolumn{4}{c|}{\bf Communication (1-n)$\times$2} &  \multicolumn{4}{c}{\bf Communication (1-n)$\times$4}\\
	\cline{2-13}
	& T & T(sd) & It. & It.(sd) & T & T(sd) & It. & It.(sd) & T & T(sd) & It. & It.(sd) \\	
	\hline
	250 & 0.16 & 0.032 & 2,621 & 894 & 0.15 & 0.036 & 2,459 & 892 & 0.15 & 0.036 & 2,494 & 547\\
	500 & 0.20 & 0.040 & 1,592 & 428 & 0.19 & 0.053 & 1,521 & 539 & 0.18 & 0.057 & 1,719 & 593\\
	1000 & 0.26 & 0.055 & 1,329 & 286 & 0.25 & 0.046 & 1,435 & 369 & 0.23 & 0. 056 & 1,400 & 426\\
	3000 & 1.26 & 0.078 & 1,657 & 212 & 1.22 & 0.101 & 1,598 & 249 & 1.20 & 0.078 & 1,704 & 252\\
	6000 & 4.40 & 0.118 & 2,771 & 197 & 4.35 & 0.127 & 2,840 & 148 & 4.33 & 0.120 & 2,975 & 188\\	
	\hline
\end{tabular}
}
\caption{Simple \commstr{} \oneTn{} in one, two and four groups, for \NQP}\label{tab:nqueens_simplecomm1n}
\end{table}

\separation

In the following experiment, another \commstr{} was implemented. %It is very similar to the one applied to \SGP{}, but in this case, 
\new{Solvers into the \soset{} use the same neighborhood \om{} $V_{PAS}(m)$ but with different values of $m$, and different selection functions. In this \commstr{} solvers are both senders and receivers (see Algorithm~\ref{as:nq_cyc}), so a cyclic exchange of the current configuration is performed between these two different solvers. A set of solvers, using the neighborhood \om{} $V_{PAS}(m)$ with a small value of $m$ and using the selection \om{} $S_{best}$, have the role of \textit{companion} solvers, \ie the small value of $m$ provides to these solvers a slow convergence, but given a configuration with high cost, they are able to obtain another with smaller cost very quick.
Other set of solvers is composed by standard solvers, \ie solver with a structure very similar to the one used for non communicating experiments: the same value of $m$ and the selection \om{} is $S_{best}$.}

During the design process of the \commstrs{} (Algorithms~\ref{comm:nqueens_cyc_11}, and ~\ref{comm:nqueens_cyc_1n}), many experiments were launched to select \begin{inparaenum} \item the percentage of variables that the companion solver swaps with the culprit one, when executing the neighborhood \om{} ($m$, it was decided to be $1$), \item the number of companion solvers to connect with the standard one, for the \commstr{} using operator \oneTn{} (it was decided to be $2$ as we can see in Algorithm~\ref{comm:nqueens_cyc_1n}), and \item the frequency of the communication, \ie the value $K_2$ in Algorithm~\ref{as:nq_cyc} (it was decided to be 5). \end{inparaenum} 

\begin{algorithm}[h]
\dontprintsemicolon
\SetNoline
\SetKwProg{myproc}{\tet{\bf abstract solver}}{\tet{\bf begin}}{\tet{\bf end}}
\myproc{as\_cyc \tcp*{{\sc Itr} $\rightarrow$ number of iterations}
	\tet{\bf computation} : $I, V, S, A$\; %\tcp*{{\sc Sci} $\rightarrow$ number of iterations with the same cost}
	\tet{\bf communication} : $C.M.$\;}{%
	$I \poslop{\mapsto}$
		\whileinline{$\left(\textbf{\Iter < } K_1\right)$}{$ V \poslop{\mapsto} S \poslop{\mapsto} \left[A \poslopcond{\Iter \% K_2} \left[\llparenthesis A \rrparenthesis^d \poslop{m} C.M.\right]\right]$}
}
\tet{\bf solver} \solverposl{standard} \tet{\bf implements} as\_cyc\;
\algoindent \tet{\bf computation} : $I_{perm}, V_{PAS}(2.5), S_{first}, A_{AI}$ \;
\algoindent \tet{\bf communication}: $CM_{last}$\;
\tet{\bf solver} \solverposl{companion} \tet{\bf implements} as\_cyc\;
\algoindent \tet{\bf computation} : $I_{perm}, V_{PAS}(1), S_{best}, A_{AI}$ \;
\algoindent \tet{\bf communication}: $CM_{last}$\;
\caption{Solvers for cyclic \commstr{} to solve \NQP{}}\label{as:nq_cyc}
\end{algorithm}

\begin{algorithm}[H]
\dontprintsemicolon
\SetNoline
$\left[\eqsolverposl{companion}\posldot A\right] \onetoone \left[\eqsolverposl{standard}\posldot C.M.\right]20;$\;
$\left[\eqsolverposl{standard}\posldot A\right] \onetoone \left[\eqsolverposl{companion}\posldot C.M.\right]20;$
\caption{Cyclic \commstr{} \oneTone{} for \NQP}\label{comm:nqueens_cyc_11}
\end{algorithm}

\begin{algorithm}[h]
\dontprintsemicolon
\SetNoline
$\left[\eqsolverposl{companion}\posldot A(2)\right] \oneton \left[\eqsolverposl{standard}\posldot C.M.\right]13;$\;
$\left[\eqsolverposl{standard}\posldot A\right] \oneton \left[\eqsolverposl{companion}\posldot C.M.(2)\right]13;$
\caption{Cyclic \commstr{} \oneTn{} for \NQP}\label{comm:nqueens_cyc_1n}
\end{algorithm}

\begin{table}[h]
\centering 
\renewcommand{\arraystretch}{1}
\newcommand{\cwnq}{1.1cm}
%\resizebox{\columnwidth}{!}{%
\begin{tabular}{p{1.3cm}|R{\cwnq}R{\cwnq}R{\cwnq}R{\cwnq}|R{\cwnq}R{\cwnq}R{\cwnq}R{\cwnq}} %|R{\cwnq}}
	\hline %\noalign{\smallskip}	
	\multirow{2}{*}{\footnotesize{\centering {\bf Instance}}} & \multicolumn{4}{c|}{\bf Communication 1-1} & \multicolumn{4}{c}{\bf Communication 1-n}\\ %&\multirow{2}{*}{\centering {\bf I.R.}}\\
	\cline{2-9}
	& T & T(sd) & It. & It.(sd) & T & T(sd) & It. & It.(sd)\\ %&\\	
	\hline
	250 & \good{0.09} & 0.021 & 1,169 & 254 & 0.10 & 0.021 & 1,224 & 254 \\ % & 2.00\\ 
	500 & \good{0.14} & 0.027 & 864 & 121 & 0.15 & 0.030 & 977 & 220 \\ % & 1.65\\
	1000 & 0.22 & 0.041 & 889 & 247 & \good{0.21} & 0.056 & 807 & 196 \\ % & 1.39\\
	3000 & 1.25 & 0.090 & 1,602 & 90 & \good{1.02} & 0.145 & 1,613 & 206 \\ % & 1.17\\
	6000 & 4.83 & 0.121 & 2,938 & 746 & \good{4.24} & 0.746 & 2,537 & 779 \\ % & 1.01\\	
	\hline
\end{tabular}
%}
\caption{Cyclic \commstr{} for \NQP}\label{tab:nqueens_cyc}
\end{table}

\begin{table}[h]
\centering 
\renewcommand{\arraystretch}{1}
\newcommand{\cwnq}{1.1cm}
\begin{tabular}{p{1.5cm}|R{\cwnq}R{\cwnq}R{\cwnq}R{\cwnq}R{\cwnq}}
	\cline{2-6}
	\multirow{2}{*}{\footnotesize{}} & \multicolumn{5}{c}{\bf Instances}\\
	\cline{2-6}
	& 250 & 500 & 1000 & 3000 & 6000 \\	
	\hline
	\hline
	{\bf I.R} & 2.00 & 1.65 & 1.39 & 1.17 & 1.01 \\ 
	{\bf P.E.C.} & 77 & 67 & 67 & 60 & 57 \\
	\hline
\end{tabular}
\caption{Improvement rate and percentage of winner receiver solvers for \NQP}\label{tab:nqueens_stat}
\end{table}

With this experiment, it was possible to find a \commstr{} which improves runtimes significantly, but only for small instances of the problem. %where the number of solutions, with respect to the order $N$, is lower. 
\new{Results in Table~\ref{tab:nqueens_cyc} confirm experimentally the hypothesis already introduced, which propose the higher the size of the problem is, (and hence, the number ef solutions inside the search space with respect to $N$) the lower the gain using communication during the search process is.} 

\new{Table~\ref{tab:nqueens_stat} shows how the \textit{improvement ratio} (column \textbf{I.R.}) decreases with the instance order $N$. This ratio was computed using the following equation:}

\[
\text{\bf I.R.}=\frac{\mbox{runtime without communication}}{\frac{\left(\mbox{runtime using communication 1-1} + \mbox{runtime using communication 1-n}\right)}{2}}
\] 

\new{For all instances, the \posl's behavior solving this problem is the same: the current configuration's cost descrives a steady dcline, until the search get trapped into an \textit{apparent} local minimum, hard to escape from. At this point, the communication takes place, providing an intensification factor, decisive to escaping from the apparent local minimum: the configuration of the trapped (standard) solver is sent to all companion solvers and they provide an improved configuration fast enough back to the standard solver. The difference between behaviors of different instances is the following: the smaller the instance is, the faster the standard solver gets trapped into this \textit{apparent} local minimum. It implies that the communication takes place earlier and then it is more effective.}

\new{The percentage of the receiver solvers that were able to find the solution before the others did, was significant. It endorses hypotesis of the improvement thanks to the communication, as we can see in Table~\ref{tab:nqueens_stat} (see also Appendix~\ref{app:nqp}, Figures~\ref{fig:bars_nq} and \ref{barplot:6000}). Furthermore, the row \textbf{P.E.C} (\textit{Percentage of Effective Communication}) shows how this percentage decreases together with $N$.}

%\pgfplotsset{
%	myStyle/.style={grid=major,font=\Large}, ylabel= Communication rate,
%	xlabel=Number of cores,
%	legend style={at={(0.7,0.9)},
%	anchor=north}
%}

%\begin{figure}
%\centering
%\begin{tikzpicture} [scale=0.7]
%\begin{groupplot}[
%group style={
%	group name=my plots,
%	group size=1 by 5,
%	xlabels at=edge bottom,
%	xticklabels at=edge bottom,		
%	ylabels at=edge left,
%	yticklabels at=edge left,
%	vertical sep=0pt
%},
%legend style={at={(0.32,0.40)},anchor=north, legend columns=2},
%footnotesize,
%width=14cm,
%height=4.5cm,
%xlabel=\% of communicating solvers,
%ylabel= \empty,
%xmin=-5,
%xmax=105,
%ymin=0,	
%ymax=30,
%ytick={0,10,...,20},
%xtick={0,25,50,100},
%tickpos=left,
%ytick align=outside,
%xtick align=outside]
%
%\nextgroupplot %2000
%[ymin=5.6, ymax=6.2, ytick={5.7,5.8,5.9,6.0,6.1,6.2}, cycle list ={{red, mark options={fill=red,scale=0.8},mark=*}, {blue, mark options={fill=blue,scale=0.8},mark=*}, {green, mark options={fill=green,scale=0.8},mark=*}, {orange, mark options={fill=orange,scale=0.8},mark=x}}]
%\addlegendentry{1 to 1}
%\addplot coordinates{(0,6.15) (25,6.05) (50,6.01) (100,5.92)};
%\addlegendentry{1 to N}
%\addplot coordinates{(0,6.15) (25,6.07) (50,5.98) (100,6.01)};
%
%\nextgroupplot %3000
%[ymin=13.5, ymax=14.1, ytick={13.6,13.7,13.8,13.9,14.0,14.1}, cycle list ={{red, mark options={fill=red,scale=0.8},mark=*}, {blue, mark options={fill=blue,scale=0.8},mark=*}, {green, mark options={fill=green,scale=0.8},mark=*}, {orange, mark options={fill=orange,scale=0.8},mark=x}}]
%\addplot coordinates{(0,14.06) (25,13.89) (50,13.91) (100,13.67)};
%\addplot coordinates{(0,14.06) (25,13.97) (50,13.96) (100,13.79)};
%
%\nextgroupplot %4000
%[ymin=24.9, ymax=25.5, ytick={25.0,25.1,25.2,25.3,25.4,25.5}, cycle list ={{red, mark options={fill=red,scale=0.8},mark=*}, {blue, mark options={fill=blue,scale=0.8},mark=*}, {green, mark options={fill=green,scale=0.8},mark=*}, {orange, mark options={fill=orange,scale=0.8},mark=x}}, ylabel= runtime (secs)]
%\addplot coordinates{(0,25.46) (25,25.25) (50,25.14) (100,25.11)};
%\addplot coordinates{(0,25.46) (25,25.30) (50,25.29) (100,25.17)};
%
%\nextgroupplot %5000
%[ymin=39.5, ymax=40.7, ytick={39.6,39.8,40.0,40.2,40.4,40.6}, cycle list ={{red, mark options={fill=red,scale=0.8},mark=*}, {blue, mark options={fill=blue,scale=0.8},mark=*}, {green, mark options={fill=green,scale=0.8},mark=*}, {orange, mark options={fill=orange,scale=0.8},mark=x}}]
%\addplot coordinates{(0,40.57) (25,40.38) (50,40.33) (100,39.62)};
%\addplot coordinates{(0,40.57) (25,40.45) (50,40.37) (100,39.88)};
%
%\nextgroupplot %6000
%[ymin=58.8, ymax=60.4, ytick={58.8,59.1,59.4,59.7,60.0,60.3}, cycle list ={{red, mark options={fill=red,scale=0.8},mark=*}, {blue, mark options={fill=blue,scale=0.8},mark=*}, {green, mark options={fill=green,scale=0.8},mark=*}, {orange, mark options={fill=orange,scale=0.8},mark=x}}]
%\addplot coordinates{(0,60.10) (25,59.28) (50,58.97) (100,58.97)};
%\addplot coordinates{(0,60.10) (25,59.77) (50,59.53) (100,59.16)};
%		
%\end{groupplot}
%\end{tikzpicture}
%\caption[]{Runtime means of instances \\2000-, 3000-, 4000-, 5000- and 6000-queens}
%\label{fig:results_nq}
%\end{figure}


%\modified{Results in Table~\ref{tab:nqueens_dic}} show that this strategy is effective to solve the \nqp{} improving the runtimes already obtained in the previews experiment. In the resolution of this problem, the improvement rate of the current configuration cost is very slow (yet stable). The \textit{partial} solvers work only on a section of the configuration, and for that reason, they are able to obtain configuration with costs considerably lower than the obtained by the {\it full} solver more quickly. This characteristic is taken into account: \textit{partial} solvers send their obtained configurations to the \textit{full} solvers. By doing this, the improvement rate of the current configuration can be accelerated at the beginning of the search.