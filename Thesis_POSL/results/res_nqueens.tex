In this section I present the performed study using \nqp{} (\NQP) as a benchmark. The \commstr{} analyzed here consists in exchanging cyclically the configuration between solvers using different neighborhood functions, in order to accelerate the process of generating very promising configurations. Final obtained results show that this \commstr{} works pretty well for some instances of this problem.

\subsection{Problem definition}

The \nqp{} (\NQP) asks how to place $N$ queens on a chess board so that none of them can hit any other in one move. This problem was introduced in 1848 by the chess player Max Bezzelas as the \textit{8-queen problem}, and years latter it was generalized as \textit{N-queen problem} by Franz Nauck. Since then many mathematicians, including Gauss, have worked on this problem. It finds a lot of applications, e.g., parallel memory storage schemes, traffic control, deadlock prevention, neural networks, constraint satisfaction problems, among others \cite{Bell2009}. Some studies suggest that the number of solution grows exponentially with the number of queens ($N$), but local search methods have been shown very good results for this problem \cite{Sosic1994}. For that reason we tested some communication strategies using \posl{}, to solve a problem relatively easy to solve using non communication strategies.

The cost function for this benchmark was implemented in C++ based on the current implementation of {\it Adaptive Search}\footnote{It is based on the code from Daniel D\'{i}az available at \href{https://sourceforge.net/projects/adaptivesearch/}{https://sourceforge.net/projects/adaptivesearch/}}.

\subsection{Experiments and results}

To handle this problem, some modules used for the \sgp{} have been reused: the selection \oms{} $S_{first}$ and $S_{best}$, and the acceptance \om{} $A_{AI}$. It was used a simple \as{} presented in Algorithm~\ref{as:nq}:

\begin{algorithm}[H]
\dontprintsemicolon
\SetNoline
\SetKwProg{myproc}{\tet{\bf abstract solver}}{\tet{\bf begin}}{\tet{\bf end}}
\myproc{as\_simple \tcp*{{\sc Itr} $\rightarrow$ number of iterations}
	\tet{\bf computation} : $I, V, S, A$\tcp*{{\sc Sci} $\rightarrow$ number of iterations with the same cost}}{
	$I \poslop{\mapsto}$
		\whileinline{$\left(\textbf{\Iter < } K_1\right)$}{$ V \poslop{\mapsto} S \poslop{\mapsto} A$}	
}
\tet{\bf solver} \solverposl{as} \tet{\bf implements} as\_simple\;
\algoindent \tet{\bf computation} : $I_{perm}, V_{AS}, S_{first}, A_{AI}$ \;
\tet{\bf solver} \solverposl{selective} \tet{\bf implements} as\_simple\;
\algoindent \tet{\bf computation} : $I_{perm}, V_{PAS}(p), S_{first}, A_{AI}$ \; 
%\tet{\bf connection}: $CM_{last}$\;
\caption{\As{} for \NQP}\label{as:nq}
\end{algorithm}

Solvers used for the experiments without communications, are presented in Algorithm~\ref{as:nq}, where the \as{} is instantiated in the solver \solverposl{as} with the neighborhood \om{} $V_{AS}$, which given a configuration, returns a neighborhood $V\left(s\right)$ swapping the variable which contributes the most to the cost, with all others. This solver was able to find solutions but taking too much time (a minute for 6000-queens, for example). For that reason it was implemented a neighborhood \om{} $S_{PAS}(p)$ which performs the same algorithm of $S_{AS}$, but instead of generating neighbors swapping the most costly variable with all others, it is swapped only with a percentage of rest of variables. Solver \solverposl{selective} instantiates the \as{} with this \om, showing much better results than \solverposl{as}.

Table~\ref{tab:nqueens_seqpar} presents results of sequential and parallel runs, using \solverposl{selective} with a tunned value of $p=2.5$. Results show that the improvement of the parallel scheme using \posl{} is not big. While the number of solutions of this problem is only known for the very small value of $N = 23$, studies suggest that the number of solutions grows exponentially with $N$. It implies that as the problem grows in order, it becomes easier to solve through local search methods. The behavior of \posl{} solving this problem matches  with this hypothesis: the search process solving larger instances is more stable and the convergence is direct. In a well spread search space with a lot of solutions, the parallelism using 40 cores do not provide a lot of improvement. In that sense, \modified{as a future work, experiments using \posl{} to solve \NQP{} in parallel with more cores are planned.}

\begin{table}[t]
\centering 
\renewcommand{\arraystretch}{1}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{p{1.3cm}|R{1.3cm}R{1.3cm}R{1.3cm}R{1.3cm}|R{1.3cm}R{1.3cm}R{1.3cm}R{1.3cm}}
	\hline %\noalign{\smallskip}	
	\multirow{2}{*}{\footnotesize{\centering {\bf Instance}}} & \multicolumn{4}{c|}{\bf Sequential} & \multicolumn{4}{c}{\bf Parallel} \\
	\cline{2-9}
	& T & T(sd) & It. & It.(sd) & T & T(sd) & It. & It.(sd) \\	
	\hline
	250 & 0.29 & 0.072 & 8,898 & 2,158 & 0.19 & 0.003 & 4,139 & 913 \\
	500 & 0.35 & 0.087 & 4,203 & 998 & 0.24 & 0.036 & 2,675 & 366 \\
	1000 & 0.35 & 0.126 & 2,766 & 445 & 0.30 & 0.037 & 2,102 & 222 \\
	3000 & 1.50 & 0.138 & 2,191 & 77 & 1.33 & 0.055 & 2,168 & 71 \\
	6000 & 4.71 & 0.183 & 3,339 & 51 & 4.57 & 0.123 & 3,323 & 43 \\
	\hline
\end{tabular}
}
\caption{Results for \NQP{} (sequential and parallel without communication)}\label{tab:nqueens_seqpar}
\end{table}

\separation

In order to test the cooperative approach with this problem, a first and simple experiment was performed. Using the previous defined \as{}, communicating solvers were built, to create a simple \commstr{} in which the shared information is the current configuration, and it is communicated in one sense (from sender solvers to receivers). Algorithms~\ref{as:nq_sender}~and~\ref{as:nq_receiver} show that the communication is performed while applying the acceptance criterion. We design different communication strategies: 
\begin{itemize}
\item a set of sender solvers sending information to receiver solvers, using operator \oneTone{} (see see Algorithm~\ref{comm:nqueens_simple_11}) and operator \oneTn{} (see Algorithm~\ref{comm:nqueens_simple_1nk} with $K=1$)
\item some sets of sender solvers sending information to receiver solvers, using operator \oneTn{} (see see Algorithm~\ref{comm:nqueens_simple_1nk}), with $K\in\left\{2, 4\right\}$
\end{itemize}

\begin{algorithm}[H]
\dontprintsemicolon
\SetNoline
\SetKwProg{myproc}{\tet{\bf abstract solver}}{\tet{\bf begin}}{\tet{\bf end}}
\myproc{as\_sender \tcp*{{\sc Itr} $\rightarrow$ number of iterations}
	\tet{\bf computation} : $I, V, S, A$\tcp*{{\sc Sci} $\rightarrow$ number of iterations with the same cost}}{
	$I \poslop{\mapsto}$
		\whileinline{$\left(\textbf{\Iter < } K_1\right)$}{$ V \poslop{\mapsto} S \poslop{\mapsto} \llparenthesis A \rrparenthesis^d$}	
}
\tet{\bf solver} \solverposl{sender} \tet{\bf implements} as\_sender\;
\algoindent \tet{\bf computation} : $I_{perm}, V_{PAS}(p), S_{first}, A_{AI}$ \;
\caption{Sender solver for \NQP{} (simple \commstr)}\label{as:nq_sender}
\end{algorithm}

\begin{algorithm}[H]
\dontprintsemicolon
\SetNoline
\SetKwProg{myproc}{\tet{\bf abstract solver}}{\tet{\bf begin}}{\tet{\bf end}}
\myproc{as\_receiver \tcp*{{\sc Itr} $\rightarrow$ number of iterations}
	\tet{\bf computation} : $I, V, S, A$\tcp*{{\sc Sci} $\rightarrow$ number of iterations with the same cost}
	\tet{\bf communication} : $C.M.$\;}{%
	$I \poslop{\mapsto}$
		\whileinline{$\left(\textbf{\Iter < } K_1\right)$}{$ V \poslop{\mapsto} S \poslop{\mapsto} \left[A \poslopcond{\Iter \% K_2} \left[A \poslop{m} C.M.\right]\right]$}
}
\tet{\bf solver} \solverposl{receiver} \tet{\bf implements} as\_receiver\;
\algoindent \tet{\bf computation} : $I_{perm}, V_{PAS}(p), S_{first}, A_{AI}$ \;
\algoindent \tet{\bf communication}: $CM_{last}$\;
\caption{Receiver solver for \NQP{} (simple \commstr)}\label{as:nq_receiver}
\end{algorithm}

\begin{algorithm}[H]
\dontprintsemicolon
\SetNoline
$\left[\eqsolverposl{sender}\posldot A\right] \onetoone \left[\eqsolverposl{receiver}\posldot C.M.\right]20;$
\caption{Simple \commstr{} \oneTone{} for \NQP}\label{comm:nqueens_simple_11}
\end{algorithm}

\begin{algorithm}[H]
\dontprintsemicolon
\SetNoline
$\left[\eqsolverposl{sender}\posldot A(\tfrac{20}{K})\right] \oneton \left[\eqsolverposl{receiver}\posldot C.M.(\tfrac{20}{K})\right]K;$
\caption{Simple \commstr{} \oneTn{} for \NQP}\label{comm:nqueens_simple_1nk}
\end{algorithm}

Tables~\ref{tab:nqueens_simplecomm11} and ~\ref{tab:nqueens_simplecomm1n} show how the communication improve the non communicating results in terms of runtime and iterations, but this improvement is not significant. In contrast to \SGP, \posl{} does not get trapped so often into local minima during the resolution of \NQP{}. For that reason, the shared information, once received and accepted by the receivers solvers, does not improves largely the current cost.

\begin{table}[t]
\centering 
\renewcommand{\arraystretch}{1}
\newcommand{\cwnq}{1.1cm}
\begin{tabular}{p{1.3cm}|R{\cwnq}R{\cwnq}R{\cwnq}R{\cwnq}}
	\hline 
	\multirow{2}{*}{\footnotesize{\centering {\bf Instance}}} & \multicolumn{4}{c}{\bf Communication 1-1} \\
	\cline{2-5}
	& T & T(sd) & It. & It.(sd) \\	
	\hline
	250 & 0.18 & 0.040 & 3,433 & 697 \\ 
	500 & 0.25 & 0.047 & 2,216 & 427 \\
	1000 & 0.26 & 0.056 & 1,735 & 424\\
	3000 & 1.21 & 0.088 & 1,873 & 227\\
	6000 & 4.38 & 0.111 & 3,178 & 121\\	
	\hline
\end{tabular}
\caption{Simple \commstr{} \oneTone{} for \NQP}\label{tab:nqueens_simplecomm11}
\end{table}

\begin{table}[h]
\centering 
\renewcommand{\arraystretch}{1}
\newcommand{\cwnq}{1.1cm}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{p{1.3cm}|R{\cwnq}R{\cwnq}R{\cwnq}R{\cwnq}|R{\cwnq}R{\cwnq}R{\cwnq}R{\cwnq}|R{\cwnq}R{\cwnq}R{\cwnq}R{\cwnq}}
	\hline %\noalign{\smallskip}	
	\multirow{2}{*}{\footnotesize{\centering {\bf Instance}}} & \multicolumn{4}{c|}{\bf Communication 1-n} & \multicolumn{4}{c|}{\bf Communication (1-n)$\times$2} &  \multicolumn{4}{c}{\bf Communication (1-n)$\times$4}\\
	\cline{2-13}
	& T & T(sd) & It. & It.(sd) & T & T(sd) & It. & It.(sd) & T & T(sd) & It. & It.(sd) \\	
	\hline
	250 & 0.16 & 0.032 & 2,621 & 894 & 0.15 & 0.036 & 2,459 & 892 & 0.15 & 0.036 & 2,494 & 547\\
	500 & 0.20 & 0.040 & 1,592 & 428 & 0.19 & 0.053 & 1,521 & 539 & 0.18 & 0.057 & 1,719 & 593\\
	1000 & 0.26 & 0.055 & 1,329 & 286 & 0.25 & 0.046 & 1,435 & 369 & 0.23 & 0. 056 & 1,400 & 426\\
	3000 & 1.26 & 0.078 & 1,657 & 212 & 1.22 & 0.101 & 1,598 & 249 & 1.20 & 0.078 & 1,704 & 252\\
	6000 & 4.40 & 0.118 & 2,771 & 197 & 4.35 & 0.127 & 2,840 & 148 & 4.33 & 0.120 & 2,975 & 188\\	
	\hline
\end{tabular}
}
\caption{Simple \commstr{} \oneTn{} for \NQP}\label{tab:nqueens_simplecomm1n}
\end{table}

\separation

In the following experiment, with the goal of improving results, another \commstr{} was implemented, very similar to the one applied to \SGP{}, but in this case, with solvers using the same neighborhood function $V_{PAS}(p)$ but with different values of $p$ and different selection functions. In this \commstr{} a cyclic exchange of the current configuration is performed between to different solvers. One solver \textit{companion} using the neighborhood \om{} $V_{PAS}(p)$ with a smaller value of $p$ and using the selection \om{} $S_{best}$, meaning that it is able to find promising configuration faster, but its convergence is slower. 
The other solver is very similar to the one used for non communicating experiments, but in this \commstr{} solvers are both senders and receivers (see Algorithm~\ref{as:nq_cyc}). Before designing \commstrs{} (Algorithms~\ref{comm:nqueens_cyc_11}, and ~\ref{comm:nqueens_cyc_1n}), many experiments were launched to select: \begin{inparaenum} \item The percentage of variables that the companion solver swaps with the culprit one, when executing the neighborhood \om{} ($p$). This value was decided to be $1$. \item The number of companion solvers to connect with the standard one, for the \commstr{} using operator \oneTn. This vale was decide to be $2$, as we can see in Algorithm~\ref{comm:nqueens_cyc_1n}. \end{inparaenum} 

\begin{algorithm}[H]
\dontprintsemicolon
\SetNoline
\SetKwProg{myproc}{\tet{\bf abstract solver}}{\tet{\bf begin}}{\tet{\bf end}}
\myproc{as\_cyc \tcp*{{\sc Itr} $\rightarrow$ number of iterations}
	\tet{\bf computation} : $I, V, S_1, S_2, A$\tcp*{{\sc Sci} $\rightarrow$ number of iterations with the same cost}
	\tet{\bf communication} : $C.M.$\;}{%
	$I \poslop{\mapsto}$
		\whileinline{$\left(\textbf{\Iter < } K_1\right)$}{$ V \poslop{\mapsto} S \poslop{\mapsto} \left[A \poslopcond{\Iter \% K_2} \left[\llparenthesis A \rrparenthesis^d \poslop{m} C.M.\right]\right]$}
}
\tet{\bf solver} \solverposl{standard} \tet{\bf implements} as\_cyc\;
\algoindent \tet{\bf computation} : $I_{perm}, V_{PAS}(2.5), S_{first}, A_{AI}$ \;
\algoindent \tet{\bf communication}: $CM_{last}$\;
\tet{\bf solver} \solverposl{companion} \tet{\bf implements} as\_cyc\;
\algoindent \tet{\bf computation} : $I_{perm}, V_{PAS}(1), S_{best}, A_{AI}$ \;
\algoindent \tet{\bf communication}: $CM_{last}$\;
\caption{Solvers for cyclic \commstr{} to solve \NQP{}}\label{as:nq_cyc}
\end{algorithm}

\begin{algorithm}[H]
\dontprintsemicolon
\SetNoline
$\left[\eqsolverposl{companion}\posldot A\right] \onetoone \left[\eqsolverposl{standard}\posldot C.M.\right]20;$\;
$\left[\eqsolverposl{standard}\posldot A\right] \onetoone \left[\eqsolverposl{companion}\posldot C.M.\right]20;$
\caption{Cyclic \commstr{} \oneTone{} for \NQP}\label{comm:nqueens_cyc_11}
\end{algorithm}

\begin{algorithm}[h]
\dontprintsemicolon
\SetNoline
$\left[\eqsolverposl{companion}\posldot A(2)\right] \oneton \left[\eqsolverposl{standard}\posldot C.M.\right]13;$\;
$\left[\eqsolverposl{standard}\posldot A\right] \oneton \left[\eqsolverposl{companion}\posldot C.M.(2)\right]13;$
\caption{Cyclic \commstr{} \oneTn{} for \NQP}\label{comm:nqueens_cyc_1n}
\end{algorithm}

\begin{table}[h]
\centering 
\renewcommand{\arraystretch}{1}
\newcommand{\cwnq}{1.1cm}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{p{1.3cm}|R{\cwnq}R{\cwnq}R{\cwnq}R{\cwnq}|R{\cwnq}R{\cwnq}R{\cwnq}R{\cwnq}|R{\cwnq}}
	\hline %\noalign{\smallskip}	
	\multirow{2}{*}{\footnotesize{\centering {\bf Instance}}} & \multicolumn{4}{c|}{\bf Communication 1-1} & \multicolumn{4}{c|}{\bf Communication 1-n}&\multirow{2}{*}{\centering {\bf I.R.}}\\
	\cline{2-9}
	& T & T(sd) & It. & It.(sd) & T & T(sd) & It. & It.(sd)&\\	
	\hline
	250 & \good{0.09} & 0.021 & 1,169 & 254 & 0.10 & 0.021 & 1,224 & 254 & 2.00\\ 
	500 & \good{0.14} & 0.027 & 864 & 121 & 0.15 & 0.030 & 977 & 220 & 1.65\\
	1000 & 0.22 & 0.041 & 889 & 247 & \good{0.21} & 0.056 & 807 & 196& 1.39\\
	3000 & 1.25 & 0.090 & 1,602 & 90 & \good{1.02} & 0.145 & 1,613 & 206 & 1.17\\
	6000 & 4.83 & 0.121 & 2,938 & 746 & \good{4.24} & 0.746 & 2,537 & 779 & 1.01\\	
	\hline
\end{tabular}
}
\caption{Cyclic \commstr{} for \NQP}\label{tab:nqueens_cyc}
\end{table}

With this experiment, it was possible to find a \commstr{} which improves runtimes significantly, but only for small instances of the problem, where the number of solutions, with respect to the order $N$, is lower. This result confirms experimentally the hypothesis already introduced, which propose that as the size of the problem grows, (and with it, the number ef solutions inside the search space with respect to $N$) lower is the gain using communication during the search process. Table~\ref{tab:nqueens_cyc} shows how the \textit{improvement ratio} (column \textbf{I.R.}) decreases with the instance order $N$. This ratio was computed using the following equation:

\[
\frac{\mbox{runtime without communication}}{\frac{\left(\mbox{runtime using communication 1-1} + \mbox{runtime using communication 1-n}\right)}{2}}
\] 

%\pgfplotsset{
%	myStyle/.style={grid=major,font=\Large}, ylabel= Communication rate,
%	xlabel=Number of cores,
%	legend style={at={(0.7,0.9)},
%	anchor=north}
%}

%\begin{figure}
%\centering
%\begin{tikzpicture} [scale=0.7]
%\begin{groupplot}[
%group style={
%	group name=my plots,
%	group size=1 by 5,
%	xlabels at=edge bottom,
%	xticklabels at=edge bottom,		
%	ylabels at=edge left,
%	yticklabels at=edge left,
%	vertical sep=0pt
%},
%legend style={at={(0.32,0.40)},anchor=north, legend columns=2},
%footnotesize,
%width=14cm,
%height=4.5cm,
%xlabel=\% of communicating solvers,
%ylabel= \empty,
%xmin=-5,
%xmax=105,
%ymin=0,	
%ymax=30,
%ytick={0,10,...,20},
%xtick={0,25,50,100},
%tickpos=left,
%ytick align=outside,
%xtick align=outside]
%
%\nextgroupplot %2000
%[ymin=5.6, ymax=6.2, ytick={5.7,5.8,5.9,6.0,6.1,6.2}, cycle list ={{red, mark options={fill=red,scale=0.8},mark=*}, {blue, mark options={fill=blue,scale=0.8},mark=*}, {green, mark options={fill=green,scale=0.8},mark=*}, {orange, mark options={fill=orange,scale=0.8},mark=x}}]
%\addlegendentry{1 to 1}
%\addplot coordinates{(0,6.15) (25,6.05) (50,6.01) (100,5.92)};
%\addlegendentry{1 to N}
%\addplot coordinates{(0,6.15) (25,6.07) (50,5.98) (100,6.01)};
%
%\nextgroupplot %3000
%[ymin=13.5, ymax=14.1, ytick={13.6,13.7,13.8,13.9,14.0,14.1}, cycle list ={{red, mark options={fill=red,scale=0.8},mark=*}, {blue, mark options={fill=blue,scale=0.8},mark=*}, {green, mark options={fill=green,scale=0.8},mark=*}, {orange, mark options={fill=orange,scale=0.8},mark=x}}]
%\addplot coordinates{(0,14.06) (25,13.89) (50,13.91) (100,13.67)};
%\addplot coordinates{(0,14.06) (25,13.97) (50,13.96) (100,13.79)};
%
%\nextgroupplot %4000
%[ymin=24.9, ymax=25.5, ytick={25.0,25.1,25.2,25.3,25.4,25.5}, cycle list ={{red, mark options={fill=red,scale=0.8},mark=*}, {blue, mark options={fill=blue,scale=0.8},mark=*}, {green, mark options={fill=green,scale=0.8},mark=*}, {orange, mark options={fill=orange,scale=0.8},mark=x}}, ylabel= runtime (secs)]
%\addplot coordinates{(0,25.46) (25,25.25) (50,25.14) (100,25.11)};
%\addplot coordinates{(0,25.46) (25,25.30) (50,25.29) (100,25.17)};
%
%\nextgroupplot %5000
%[ymin=39.5, ymax=40.7, ytick={39.6,39.8,40.0,40.2,40.4,40.6}, cycle list ={{red, mark options={fill=red,scale=0.8},mark=*}, {blue, mark options={fill=blue,scale=0.8},mark=*}, {green, mark options={fill=green,scale=0.8},mark=*}, {orange, mark options={fill=orange,scale=0.8},mark=x}}]
%\addplot coordinates{(0,40.57) (25,40.38) (50,40.33) (100,39.62)};
%\addplot coordinates{(0,40.57) (25,40.45) (50,40.37) (100,39.88)};
%
%\nextgroupplot %6000
%[ymin=58.8, ymax=60.4, ytick={58.8,59.1,59.4,59.7,60.0,60.3}, cycle list ={{red, mark options={fill=red,scale=0.8},mark=*}, {blue, mark options={fill=blue,scale=0.8},mark=*}, {green, mark options={fill=green,scale=0.8},mark=*}, {orange, mark options={fill=orange,scale=0.8},mark=x}}]
%\addplot coordinates{(0,60.10) (25,59.28) (50,58.97) (100,58.97)};
%\addplot coordinates{(0,60.10) (25,59.77) (50,59.53) (100,59.16)};
%		
%\end{groupplot}
%\end{tikzpicture}
%\caption[]{Runtime means of instances \\2000-, 3000-, 4000-, 5000- and 6000-queens}
%\label{fig:results_nq}
%\end{figure}


%\modified{Results in Table~\ref{tab:nqueens_dic}} show that this strategy is effective to solve the \nqp{} improving the runtimes already obtained in the previews experiment. In the resolution of this problem, the improvement rate of the current configuration cost is very slow (yet stable). The \textit{partial} solvers work only on a section of the configuration, and for that reason, they are able to obtain configuration with costs considerably lower than the obtained by the {\it full} solver more quickly. This characteristic is taken into account: \textit{partial} solvers send their obtained configurations to the \textit{full} solvers. By doing this, the improvement rate of the current configuration can be accelerated at the beginning of the search.